import time
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel, Field, ConfigDict, AliasChoices
from typing import List, Optional, Dict, Any, Union
from core.services.text_processing_service_v2 import text_processing_service
from models.request import SyntaxFixRequest, BatchSyntaxFixRequest, semanticProfileRequest, BatchSemProfileRequest
from models.response import SyntaxFixResponse, BatchSyntaxFixResponse
from models.internal import AnalyzerRequest
from core.analyzer import analyzer
from utils.logging import logger
from core.services.semantic_profile import (
	generate_semantic_profile_for_passage,
	generate_semantic_profiles_batch,
)
from core.services.topic_closeness import score_topic_closeness, generate_and_score, generate_and_score_batch

router = APIRouter(tags=["revision"])

### ----------------------------- Semantic Profile ----------------------------- ###
class SemanticProfileRequest(BaseModel):
	passage_text: str = Field(..., description="ì›ë¬¸ passage í…ìŠ¤íŠ¸")


class SemanticProfileBatchRequest(BaseModel):
	passages: List[str] = Field(..., description="ì—¬ëŸ¬ ì›ë¬¸ í…ìŠ¤íŠ¸ ë°°ì—´")

class SemanticProfileResponse(BaseModel):
	discipline: str
	subtopic_1: str
	subtopic_2: str
	central_focus: List[str]
	key_concepts: List[str]
	processes_structures: Optional[str] = None
	setting_context: Optional[str] = None
	purpose_objective: Optional[str] = None
	genre_form: Optional[str] = None
	# ì˜¤ë¥˜ ë°œìƒ ì‹œ í¬í•¨ë  ìˆ˜ ìˆìŒ
	error: Optional[str] = None
 
class GenSemProfileResponse(BaseModel):
    # ìš”ì²­ ì‹œ ì „ë‹¬ë°›ì€ ê³ ìœ  ì‹ë³„ì (í•„ìˆ˜)
    request_id: str 
    # ìš”ì²­ ì‹œ ì „ë‹¬ë°›ì€ ì œëª© (ì„ íƒ ì‚¬í•­)
    title: Optional[str] = None
    
    semantic_profile: SemanticProfileResponse
    
class SemanticProfileBatchItemV2(BaseModel):
    request_id: str
    title: Optional[str] = None
    passage_text: str

class SemanticProfileBatchRequestV2(BaseModel):
    items: List[SemanticProfileBatchItemV2]

@router.post("/semantic-profile", response_model=SemanticProfileResponse)
async def generate_semantic_profile(req: SemanticProfileRequest):
	try:
		logger.info("=" * 80)
		logger.info("ğŸ“¥ [SEMANTIC PROFILE] ì—”ë“œí¬ì¸íŠ¸ ìš”ì²­ ìˆ˜ì‹ ")
		logger.info("=" * 80)
		logger.info(f"ğŸ“„ ì…ë ¥ ì§€ë¬¸ ê¸¸ì´: {len(req.passage_text)}ì")
		logger.info(f"ğŸ“„ ì…ë ¥ ì§€ë¬¸ (ì²˜ìŒ 300ì):\n{req.passage_text[:300]}...")
		logger.info("=" * 80)
		
		result = await generate_semantic_profile_for_passage(req.passage_text)
		
		logger.info("=" * 80)
		logger.info("âœ… [SEMANTIC PROFILE] ì—”ë“œí¬ì¸íŠ¸ ì‘ë‹µ ì™„ë£Œ")
		logger.info("=" * 80)
		
		return result
	except Exception as e:
		logger.error(f"âŒ [SEMANTIC PROFILE] ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=str(e))


@router.post(
	"/semantic-profile:batch",
	response_model=Union[List[SemanticProfileResponse], List[GenSemProfileResponse]]
)
async def generate_semantic_profile_batch(req: Union[SemanticProfileBatchRequestV2, SemanticProfileBatchRequest]):
	try:
		logger.info("=" * 80)
		logger.info("ğŸ“¥ [SEMANTIC PROFILE BATCH] ì—”ë“œí¬ì¸íŠ¸ ìš”ì²­ ìˆ˜ì‹ ")
		logger.info("=" * 80)
		
		# V1: ë‹¨ìˆœ ë¬¸ìì—´ ë°°ì—´
		if isinstance(req, SemanticProfileBatchRequest):
			logger.info(f"ğŸ”¢ ë°°ì¹˜ í•­ëª© ìˆ˜: {len(req.passages)}ê°œ")
			for idx, passage in enumerate(req.passages, 1):
				logger.info(f"  [{idx}] ì§€ë¬¸ ê¸¸ì´: {len(passage)}ì, ë¯¸ë¦¬ë³´ê¸°: {passage[:100]}...")
			profiles = await generate_semantic_profiles_batch(req.passages)
			logger.info("=" * 80)
			logger.info("âœ… [SEMANTIC PROFILE BATCH] ì™„ë£Œ")
			logger.info("=" * 80)
			return profiles

		# V2: ì‹ë³„ì/ì œëª©ì´ í¬í•¨ëœ ì•„ì´í…œ ë°°ì—´
		logger.info(f"ğŸ”¢ ë°°ì¹˜ í•­ëª© ìˆ˜: {len(req.items)}ê°œ")
		for idx, item in enumerate(req.items, 1):
			logger.info(f"  [{idx}] request_id: {item.request_id}, title: {item.title}, ì§€ë¬¸ ê¸¸ì´: {len(item.passage_text)}ì")
		
		texts = [item.passage_text for item in req.items]
		profiles = await generate_semantic_profiles_batch(texts)
		
		logger.info("=" * 80)
		logger.info("âœ… [SEMANTIC PROFILE BATCH] ì™„ë£Œ")
		logger.info("=" * 80)
		
		return [
			GenSemProfileResponse(
				request_id=item.request_id,
				title=item.title,
				semantic_profile=profiles[idx]
			)
			for idx, item in enumerate(req.items)
		]
	except Exception as e:
		logger.error(f"âŒ [SEMANTIC PROFILE BATCH] ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
		raise HTTPException(status_code=500, detail=str(e))


class SemanticProfileIn(BaseModel):
	"""Closeness ë¹„êµìš© ì…ë ¥ ìŠ¤í‚¤ë§ˆ.
	- purpose_objective â† (purpose_objective | purpose)
	- genre_form       â† (genre_form | genre)
	"""
	model_config = ConfigDict(populate_by_name=True)

	discipline: str
	subtopic_1: str
	subtopic_2: Optional[str] = None
	central_focus: List[str]
	key_concepts: List[str]
	processes_structures: Optional[str] = None
	setting_context: Optional[str] = None
	purpose_objective: Optional[str] = Field(default=None, validation_alias=AliasChoices("purpose_objective", "purpose"))
	genre_form: Optional[str] = Field(default=None, validation_alias=AliasChoices("genre_form", "genre"))


class TopicClosenessRequest(BaseModel):
	original_semantic_profile: SemanticProfileIn
	generated_semantic_profile: SemanticProfileIn

	
class TopicClosenessResponse(BaseModel):
	request_id: Optional[str] = None
	scoring: Dict[str, int]
	total_points: int
	closeness_label: int
	generated_semantic_profile: Optional[SemanticProfileResponse] = None


@router.post("/topic-closeness", response_model=TopicClosenessResponse)
async def topic_closeness(req: TopicClosenessRequest):
	try:
		orig = req.original_semantic_profile.model_dump()
		gen = req.generated_semantic_profile.model_dump()
		result = await score_topic_closeness(orig, gen)
		return result
	except Exception as e:
		raise HTTPException(status_code=500, detail=str(e))


class GenerateAndScoreRequest(BaseModel):
	request_id: Optional[str] = None
	original_semantic_profile: Union[SemanticProfileIn, str]
	passage_text: str


class GenerateAndScoreBatchItem(BaseModel):
	request_id: Optional[str] = None
	original_semantic_profile: Union[SemanticProfileIn, str]
	passage_text: str


@router.post("/topic-closeness:generate-and-score", response_model=TopicClosenessResponse)
async def topic_closeness_generate_and_score(req: GenerateAndScoreRequest):
	try:
		orig_input = req.original_semantic_profile
		if isinstance(orig_input, SemanticProfileIn):
			orig = orig_input.model_dump()
		else:
			orig = orig_input  # str
		result = await generate_and_score(orig, req.passage_text)
		if req.request_id is not None:
			result["request_id"] = req.request_id
		return result
	except Exception as e:
		raise HTTPException(status_code=500, detail=str(e))


class GenerateAndScoreBatchRequest(BaseModel):
	items: List[GenerateAndScoreBatchItem] = Field(..., description='[{"request_id": "optional-id", "original_semantic_profile": {...}, "passage_text": "..."}, ...]')


@router.post("/topic-closeness:generate-and-score:batch", response_model=List[TopicClosenessResponse])
async def topic_closeness_generate_and_score_batch(req: GenerateAndScoreBatchRequest):
	try:
		items = [item.model_dump() for item in req.items]
		results = await generate_and_score_batch(items)
		return results
	except Exception as e:
		raise HTTPException(status_code=500, detail=str(e))

##### ----------------------------- Revision ----------------------------- #####

@router.post(
    "/analyze",
    summary="í…ìŠ¤íŠ¸ ì§€ë¬¸ ë¶„ì„ ìš”ì²­",
    response_description="ì§€ë¬¸ ë¶„ì„ ê²°ê³¼"
)
async def analyze_text(data: AnalyzerRequest):
    """
    ì œê³µëœ í…ìŠ¤íŠ¸ë¥¼ ì™¸ë¶€ ì§€ë¬¸ ë¶„ì„ê¸° APIë¡œ ë³´ë‚´ê³ , ê·¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        logger.info(f"í…ìŠ¤íŠ¸ ë¶„ì„ ìš”ì²­: {len(data.text)} ê¸€ì")
        
        # ì™¸ë¶€ ë¶„ì„ê¸° API í˜¸ì¶œ
        result = await analyzer.analyze(data.text, data.include_syntax_analysis, data.llm_model)
        
        logger.info("í…ìŠ¤íŠ¸ ë¶„ì„ ì™„ë£Œ")
        return result
        
    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        ) 

@router.post(
    "/revise",
    response_model=SyntaxFixResponse,
    summary="êµ¬ë¬¸+ì–´íœ˜ ê²°í•© ë¦¬ë¹„ì „ ì‹¤í–‰",
    description="êµ¬ë¬¸ ìˆ˜ì • í›„ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì—¬ ì–´íœ˜ í†µê³¼ì‹œ ì¢…ë£Œ, ë¯¸í†µê³¼ì‹œ ì–´íœ˜ ë‹¨ê³„ë¡œ ë¶„ê¸°í•©ë‹ˆë‹¤."
)
async def revise(request: SyntaxFixRequest):
    logger.info("=" * 80)
    logger.info("ğŸš€ [REVISE] ì—”ë“œí¬ì¸íŠ¸ ìš”ì²­ ìˆ˜ì‹ ")
    logger.info("=" * 80)
    logger.info(f"ğŸ“„ request_id: {request.request_id}")
    logger.info(f"ğŸ“„ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(request.text)}ì")
    logger.info(f"ğŸ“„ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° (300ì):\n{request.text[:300]}...")
    logger.info("=" * 80)
    
    try:
        result = await text_processing_service.fix_revise_single(request)
        
        logger.info("=" * 80)
        logger.info("âœ… [REVISE] ì—”ë“œí¬ì¸íŠ¸ ì‘ë‹µ ì™„ë£Œ")
        logger.info("=" * 80)
        
        return result
    except Exception as e:
        logger.error(f"âŒ [REVISE] ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"revision ì¤‘ ì˜¤ë¥˜: {str(e)}")


@router.post(
    "/batch-revise",
    response_model=BatchSyntaxFixResponse,
    summary="ë°°ì¹˜ ê²°í•© ë¦¬ë¹„ì „ ì‹¤í–‰",
    description="ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ë³‘ë ¬ë¡œ ê²°í•© ë¦¬ë¹„ì „í•©ë‹ˆë‹¤."
)
async def batch_revise(request: BatchSyntaxFixRequest):
    total_start_time = time.time()
    try:
        logger.info(f"ë°°ì¹˜ ê²°í•© ë¦¬ë¹„ì „ ìš”ì²­ ìˆ˜ì‹ : request_id={request.request_id}, í•­ëª©={len(request.items)}ê°œ")
        if not request.items:
            raise HTTPException(status_code=400, detail="ì²˜ë¦¬í•  í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤")
        results = await text_processing_service.fix_revise_batch(request.items, request.max_concurrent)
        total_time = time.time() - total_start_time
        successful_items = sum(1 for r in results if r.overall_success)
        failed_items = len(results) - successful_items
        overall_success = failed_items == 0
        response = BatchSyntaxFixResponse(
            request_id=request.request_id,
            overall_success=overall_success,
            total_items=len(request.items),
            successful_items=successful_items,
            failed_items=failed_items,
            results=results,
            total_processing_time=total_time
        )
        logger.info(f"ë°°ì¹˜ ê²°í•© ë¦¬ë¹„ì „ ì™„ë£Œ: ì„±ê³µ={successful_items}, ì‹¤íŒ¨={failed_items}, ì´ì‹œê°„={total_time:.2f}ì´ˆ")
        return response
    except Exception as e:
        total_time = time.time() - total_start_time
        error_msg = str(e)
        logger.error(f"ë°°ì¹˜ ê²°í•© ë¦¬ë¹„ì „ ì‹¤íŒ¨: {error_msg}")
        return BatchSyntaxFixResponse(
            request_id=request.request_id,
            overall_success=False,
            total_items=len(request.items) if request.items else 0,
            successful_items=0,
            failed_items=len(request.items) if request.items else 0,
            results=[],
            total_processing_time=total_time,
            error_message=error_msg
        ) 
        
        