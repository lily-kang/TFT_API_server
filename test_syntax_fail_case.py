"""
syntax_fail_case ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ ì‚¬ìš©ì ë°ì´í„°ë¡œ êµ¬ë¬¸ ìˆ˜ì • ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
"""

import asyncio
import json
import os
import sys
from typing import Dict, Any
from unittest.mock import patch

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# JSON íŒŒì¼ì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
def load_test_data():
    """sample_test_data.jsonì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ"""
    try:
        with open('sample_test_data.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data['test_cases'][0]['input'], data['mock_responses']
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None

# Mock í•¨ìˆ˜ë“¤
async def mock_analyzer_analyze(text: str, include_syntax: bool = True) -> Dict[str, Any]:
    """Mock ì™¸ë¶€ ë¶„ì„ê¸° - í…ìŠ¤íŠ¸ì— ë”°ë¼ ë‹¤ë¥¸ ì‘ë‹µ"""
    test_data, mock_responses = load_test_data()
    
    # ì›ë³¸ í…ìŠ¤íŠ¸
    if "Iceland is a country full of natural beauty" in text:
        print("ğŸ“Š ì›ë³¸ í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘...")
        return {"metrics": mock_responses['analyzer_responses']['original_text']['metrics']}
    
    # í›„ë³´ 1 - ì‹¤íŒ¨ ì¼€ì´ìŠ¤ (ë¬¸ì¥ì´ ë„ˆë¬´ ì§§ìŒ)
    elif "Iceland has natural beauty" in text and "It has waterfalls and hot springs" in text:
        print("ğŸ“Š í›„ë³´ 1 ë¶„ì„ ì¤‘... (ì‹¤íŒ¨ ì˜ˆì •)")
        return {"metrics": {
            "AVG_SENTENCE_LENGTH": 6.5,  # í—ˆìš© ë²”ìœ„ ë°– (ë„ˆë¬´ ì§§ìŒ)
            "All_Embedded_Clauses_Ratio": 0.15,
            "CEFR_NVJD_A1A2_lemma_ratio": 0.60,
            "AVG_CONTENT_SYLLABLES": 2.0,
            "CL_CEFR_B1B2C1C2_ratio": 0.16,
            "PP_Weighted_Ratio": 1.0
        }}
    
    # í›„ë³´ 2 - ì„±ê³µ ì¼€ì´ìŠ¤
    elif "Iceland is beautiful" in text:
        print("ğŸ“Š í›„ë³´ 2 ë¶„ì„ ì¤‘... (ì„±ê³µ ì˜ˆì •)")
        return {"metrics": mock_responses['analyzer_responses']['improved_text']['metrics']}
    
    # í›„ë³´ 3 - ì„±ê³µ ì¼€ì´ìŠ¤
    elif "Iceland is a country with natural beauty" in text:
        print("ğŸ“Š í›„ë³´ 3 ë¶„ì„ ì¤‘... (ì„±ê³µ ì˜ˆì •)")
        return {"metrics": {
            "AVG_SENTENCE_LENGTH": 9.2,  # í—ˆìš© ë²”ìœ„ ë‚´
            "All_Embedded_Clauses_Ratio": 0.17,
            "CEFR_NVJD_A1A2_lemma_ratio": 0.59,
            "AVG_CONTENT_SYLLABLES": 2.2,
            "CL_CEFR_B1B2C1C2_ratio": 0.19,
            "PP_Weighted_Ratio": 1.3
        }}
    
    # ê¸°ë³¸ê°’ (ìˆ˜ì •ëœ í…ìŠ¤íŠ¸)
    else:
        print("ğŸ“Š ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘...")
        return {"metrics": mock_responses['analyzer_responses']['improved_text']['metrics']}

async def mock_llm_generate_multiple(prompt: str, temperatures: list) -> list:
    """Mock LLM ë‹¤ì¤‘ ìƒì„±"""
    test_data, mock_responses = load_test_data()
    candidates = mock_responses['llm_candidates']['syntax_fixed']
    
    print(f"\n=== ğŸ¤– LLM êµ¬ë¬¸ ìˆ˜ì • í”„ë¡¬í”„íŠ¸ (ê¸¸ì´: {len(prompt)} ê¸€ì) ===")
    print(prompt[:500] + "..." if len(prompt) > 500 else prompt)
    
    print(f"\n=== ğŸ“ ìƒì„±ëœ í›„ë³´ ({len(temperatures)}ê°œ) ===")
    for i, (candidate, temp) in enumerate(zip(candidates, temperatures)):
        print(f"í›„ë³´ {i+1} (temp={temp}): {candidate[:100]}...")
    
    return candidates

async def mock_llm_select_best_candidate(selection_prompt: str, temperature: float = 0.1) -> int:
    """Mock LLM í›„ë³´ ì„ íƒ"""
    test_data, mock_responses = load_test_data()
    selection = mock_responses['llm_selection']
    
    print(f"\n=== ğŸ¯ LLM í›„ë³´ ì„ íƒ í”„ë¡¬í”„íŠ¸ ===")
    print(selection_prompt[:300] + "..." if len(selection_prompt) > 300 else selection_prompt)
    print(f"\n=== âœ… ì„ íƒ ê²°ê³¼: {selection}ë²ˆ ===")
    
    return int(selection)

async def test_syntax_fail_case():
    """syntax_fail_case í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ syntax_fail_case í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    test_input, mock_responses = load_test_data()
    if not test_input:
        return
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    os.environ['OPENAI_API_KEY'] = 'test-key-for-mock'
    os.environ['DEBUG'] = 'True'
    
    # Mock ì„¤ì • - ëª¨ë“ˆ import í›„ì— íŒ¨ì¹˜
    try:
        print("ğŸ“¦ ëª¨ë“ˆ import ì¤‘...")
        
        # ëª¨ë¸ import
        from models.request import PipelineItem, MasterMetrics, ToleranceAbs, ToleranceRatio
        from core.pipeline import PipelineProcessor
        
        print("âœ… ëª¨ë“ˆ import ì„±ê³µ")
        
        # Mock íŒ¨ì¹˜ ì ìš©
        with patch('core.analyzer.analyzer.analyze', side_effect=mock_analyzer_analyze), \
             patch('core.llm.client.llm_client.generate_multiple', side_effect=mock_llm_generate_multiple), \
             patch('core.llm.client.llm_client.select_best_candidate', side_effect=mock_llm_select_best_candidate):
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
            pipeline_item = PipelineItem(
                client_id=test_input['client_id'],
                original_text=test_input['original_text'],
                title=test_input['title'],
                generated_passage=test_input['generated_passage'],
                include_syntax=test_input['include_syntax'],
                master=MasterMetrics(**test_input['master']),
                tolerance_abs=ToleranceAbs(**test_input['tolerance_abs']),
                tolerance_ratio=ToleranceRatio(**test_input['tolerance_ratio']),
                syntax_candidates=test_input['syntax_candidates'],
                lexical_candidates=test_input['lexical_candidates']
            )
            
            print("ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë³´:")
            print(f"- Client ID: {test_input['client_id']}")
            print(f"- í…ìŠ¤íŠ¸ ê¸¸ì´: {len(test_input['generated_passage'])} ê¸€ì")
            print(f"- ëª©í‘œ í‰ê·  ë¬¸ì¥ ê¸¸ì´: {test_input['master']['AVG_SENTENCE_LENGTH']} (Â±{test_input['tolerance_abs']['AVG_SENTENCE_LENGTH']})")
            print(f"- ëª©í‘œ ë‚´í¬ì ˆ ë¹„ìœ¨: {test_input['master']['All_Embedded_Clauses_Ratio']} (Â±{test_input['tolerance_ratio']['All_Embedded_Clauses_Ratio']*100:.1f}%)")
            print(f"- ëª©í‘œ A1A2 ë¹„ìœ¨: {test_input['master']['CEFR_NVJD_A1A2_lemma_ratio']} (Â±{test_input['tolerance_ratio']['CEFR_NVJD_A1A2_lemma_ratio']*100:.1f}%)")
            
            print(f"\nğŸ“Š ì˜ˆìƒ í›„ë³´ ê²€ì¦ ê²°ê³¼:")
            print(f"- í›„ë³´ 1: í‰ê·  ë¬¸ì¥ ê¸¸ì´ 6.5 â†’ âŒ FAIL (í—ˆìš©: 6.88-10.82)")
            print(f"- í›„ë³´ 2: í‰ê·  ë¬¸ì¥ ê¸¸ì´ 8.9 â†’ âœ… PASS")
            print(f"- í›„ë³´ 3: í‰ê·  ë¬¸ì¥ ê¸¸ì´ 9.2 â†’ âœ… PASS")
            print(f"- ì˜ˆìƒ: 2ê°œ í›„ë³´ í†µê³¼ â†’ LLMì´ ì„ íƒ")
            
            # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            print(f"\nğŸ”„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
            processor = PipelineProcessor()
            result = await processor.run_pipeline(pipeline_item)
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
            print(f"- Client ID: {result.client_id}")
            print(f"- ìµœì¢… ìƒíƒœ: {result.status}")
            print(f"- êµ¬ë¬¸ í†µê³¼: {result.syntax_pass}")
            print(f"- ì–´íœ˜ í†µê³¼: {result.lexical_pass}")
            print(f"- ì‹œë„ íšŸìˆ˜: êµ¬ë¬¸={result.attempts.syntax}, ì–´íœ˜={result.attempts.lexical}")
            
            if result.final_text:
                print(f"\nğŸ“ ìµœì¢… í…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì):")
                print(f"{result.final_text[:200]}...")
            
            print(f"\nğŸ“ˆ ìƒì„¸ ì§€í‘œ ê²°ê³¼:")
            print(result.detailed_result)
            
            # ì²˜ë¦¬ ê³¼ì • ì¶”ì 
            if result.trace:
                print(f"\nğŸ” ì²˜ë¦¬ ê³¼ì • ì¶”ì :")
                for i, step in enumerate(result.trace):
                    print(f"  {i+1}. {step.step}")
                    if step.metrics:
                        avg_len = step.metrics.get('AVG_SENTENCE_LENGTH', 'N/A')
                        clause_ratio = step.metrics.get('All_Embedded_Clauses_Ratio', 'N/A')
                        lexical_ratio = step.metrics.get('CEFR_NVJD_A1A2_lemma_ratio', 'N/A')
                        print(f"     ğŸ“ í‰ê·  ë¬¸ì¥ ê¸¸ì´: {avg_len}")
                        print(f"     ğŸ”— ë‚´í¬ì ˆ ë¹„ìœ¨: {clause_ratio}")
                        print(f"     ğŸ“š A1A2 ì–´íœ˜ ë¹„ìœ¨: {lexical_ratio}")
                    if step.selected:
                        print(f"     âœ… ì„ íƒëœ í…ìŠ¤íŠ¸: {step.selected[:80]}...")
            
            # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
            if result.status == "final":
                print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ! êµ¬ë¬¸ ìˆ˜ì •ì´ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                print("ğŸ¯ ê¸°ëŒ€í•œ í”Œë¡œìš°: analyze â†’ fix_syntax (í›„ë³´ ê²€ì¦ í¬í•¨) â†’ reanalyze_after_syntax")
            else:
                print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {result.status}")
                if result.error_message:
                    print(f"   ğŸ’¥ ì˜¤ë¥˜ ë©”ì‹œì§€: {result.error_message}")
                    
    except ImportError as e:
        print(f"âŒ ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
        print("ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
        print("1. pip install -r requirements.txt")
        print("2. __init__.py íŒŒì¼ë“¤ì´ ê° ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸")
        print("3. í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ê°€ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì¸ì§€ í™•ì¸")
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("=" * 70)
    print("ğŸ§ª syntax_fail_case ë‹¨ì¼ í…ŒìŠ¤íŠ¸ (í›„ë³´ ê²€ì¦ í¬í•¨)")
    print("=" * 70)
    
    asyncio.run(test_syntax_fail_case()) 