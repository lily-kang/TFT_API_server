"""
ì‹¤ì œ GPT API + ì™¸ë¶€ ë¶„ì„ê¸°ë¡œ êµ¬ë¬¸ ìˆ˜ì • íŒŒì´í”„ë¼ì¸ ì™„ì „ í…ŒìŠ¤íŠ¸
Mock ì—†ì´ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
"""

import asyncio
import json
import os
import sys
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def load_sample_data():
    """sample_test_data.jsonì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ"""
    try:
        with open('sample_test_data.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data['test_cases'][0]['input']
    except Exception as e:
        print(f"âŒ ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

async def test_full_syntax_pipeline():
    """ì‹¤ì œ APIë“¤ë¡œ ì™„ì „í•œ êµ¬ë¬¸ ìˆ˜ì • íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸš€ ì™„ì „í•œ êµ¬ë¬¸ ìˆ˜ì • íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    
    # ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ
    sample_input = load_sample_data()
    if not sample_input:
        return
    
    try:
        # ëª¨ë“ˆ import (ì„¤ì •ë„ í•¨ê»˜ ë¡œë“œë¨)
        from config.settings import settings
        from models.request import MasterMetrics, ToleranceAbs, ToleranceRatio
        from core.analyzer import analyzer
        from core.metrics import metrics_extractor
        from core.judge import judge
        from core.llm.syntax_fixer import syntax_fixer
        
        print("âœ… ëª¨ë“  ëª¨ë“ˆ import ì„±ê³µ")
        
        # OpenAI API í‚¤ í™•ì¸
        if not settings.openai_api_key or settings.openai_api_key == "your_openai_api_key_here":
            print("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            return
        
        print(f"âœ… OpenAI API í‚¤ í™•ì¸ ì™„ë£Œ (ëª¨ë¸: {settings.openai_model})")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¤ì •
        test_text = sample_input["generated_passage"]
        master = MasterMetrics(**sample_input["master"])
        tolerance_abs = ToleranceAbs(**sample_input["tolerance_abs"])
        tolerance_ratio = ToleranceRatio(**sample_input["tolerance_ratio"])
        
        print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ ì„¤ì •:")
        print(f"   ğŸ¯ ë§ˆìŠ¤í„° ì§€í‘œ:")
        print(f"      - í‰ê·  ë¬¸ì¥ ê¸¸ì´: {master.AVG_SENTENCE_LENGTH}")
        print(f"      - ë‚´í¬ì ˆ ë¹„ìœ¨: {master.All_Embedded_Clauses_Ratio}")
        print(f"      - A1A2 ì–´íœ˜ ë¹„ìœ¨: {master.CEFR_NVJD_A1A2_lemma_ratio}")
        print(f"   ğŸ“ í—ˆìš© ì˜¤ì°¨:")
        print(f"      - ì ˆëŒ€ê°’ ì˜¤ì°¨ (ë¬¸ì¥ê¸¸ì´): Â±{tolerance_abs.AVG_SENTENCE_LENGTH}")
        print(f"      - ë¹„ìœ¨ ì˜¤ì°¨ (ë‚´í¬ì ˆ): Â±{tolerance_ratio.All_Embedded_Clauses_Ratio}")
        print(f"      - ë¹„ìœ¨ ì˜¤ì°¨ (A1A2): Â±{tolerance_ratio.CEFR_NVJD_A1A2_lemma_ratio}")
        print(f"   ğŸ“ var_num_modifications: 3")
        print(f"   ğŸŒ¡ï¸ Temperature ì„¤ì •: {settings.llm_temperatures} Ã— ê° {settings.syntax_candidates_per_temperature}ê°œ")
        
        # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
        preview = test_text[:200] + "..." if len(test_text) > 200 else test_text
        print(f"\nğŸ“– ì§€ë¬¸ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°:\n{preview}")
        
        print(f"\n" + "=" * 80)
        print("ğŸ”„ ë‹¨ê³„ 1: ì§€ë¬¸ í…ìŠ¤íŠ¸ ë¶„ì„")
        print("=" * 80)
        
        start_time = time.time()
        
        # 1ë‹¨ê³„: ìƒì„±ë¬¸ í…ìŠ¤íŠ¸ ë¶„ì„
        print("ğŸŒ ì™¸ë¶€ ë¶„ì„ê¸°ë¡œ ìƒì„±ë¬¸ í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘...")
        original_analysis = await analyzer.analyze(test_text, include_syntax=True)
        original_metrics = metrics_extractor.extract(original_analysis)
        original_evaluation = judge.evaluate(original_metrics, master, tolerance_abs, tolerance_ratio)
        
        analysis_time = time.time() - start_time
        
        print(f"âœ… ì§€ë¬¸ ë¶„ì„ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {analysis_time:.2f}ì´ˆ)")
        print(f"ğŸ“Š ì›ë³¸ ì§€í‘œ:")
        print(f"   - í‰ê·  ë¬¸ì¥ ê¸¸ì´: {original_metrics.AVG_SENTENCE_LENGTH:.3f}")
        print(f"   - ë‚´í¬ì ˆ ë¹„ìœ¨: {original_metrics.All_Embedded_Clauses_Ratio:.3f}")
        print(f"   - A1A2 ì–´íœ˜ ë¹„ìœ¨: {original_metrics.CEFR_NVJD_A1A2_lemma_ratio:.3f}")
        print(f"ğŸ“ˆ ì›ë³¸ í‰ê°€:")
        print(f"   - êµ¬ë¬¸ í†µê³¼: {original_evaluation.syntax_pass}")
        print(f"   - ì–´íœ˜ í†µê³¼: {original_evaluation.lexical_pass}")
        
        # êµ¬ë¬¸ ìˆ˜ì •ì´ í•„ìš”í•œì§€ í™•ì¸
        if original_evaluation.syntax_pass == "PASS":
            print("âœ… ìƒì„±ì§€ë¬¸ í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ êµ¬ë¬¸ ì§€í‘œë¥¼ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
            print("ğŸ”š í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        print(f"\n" + "=" * 80)
        print("ğŸ”„ ë‹¨ê³„ 2: êµ¬ë¬¸ ìˆ˜ì • ìˆ˜í–‰")
        print("=" * 80)
        
        # 2ë‹¨ê³„: êµ¬ë¬¸ ìˆ˜ì • ìˆ˜í–‰
        print("ğŸ¤– GPT APIë¡œ êµ¬ë¬¸ ìˆ˜ì • ì¤‘...")
        print(f"   - Temperature ì„¤ì •: {settings.llm_temperatures} Ã— ê° {settings.syntax_candidates_per_temperature}ê°œ = ì´ {len(settings.llm_temperatures) * settings.syntax_candidates_per_temperature}ê°œ í›„ë³´ ìƒì„±")
        print("   - var_num_modifications: 3")
        
        # current_metricsë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        current_metrics_dict = {
            'AVG_SENTENCE_LENGTH': original_metrics.AVG_SENTENCE_LENGTH,
            'All_Embedded_Clauses_Ratio': original_metrics.All_Embedded_Clauses_Ratio,
            'CEFR_NVJD_A1A2_lemma_ratio': original_metrics.CEFR_NVJD_A1A2_lemma_ratio
        }
        
        syntax_start_time = time.time()
        
        try:
            # êµ¬ë¬¸ ìˆ˜ì • ì‹¤í–‰
            candidates, selected_text, final_metrics, final_evaluation = await syntax_fixer.fix_syntax(
                text=test_text,
                master=master,
                tolerance_abs=tolerance_abs,
                tolerance_ratio=tolerance_ratio,
                current_metrics=current_metrics_dict,
                referential_clauses=""  # ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •
            )
            
            syntax_time = time.time() - syntax_start_time
            
            print(f"âœ… êµ¬ë¬¸ ìˆ˜ì • ì™„ë£Œ (ì†Œìš” ì‹œê°„: {syntax_time:.2f}ì´ˆ)")
            print(f"ğŸ“ ìƒì„±ëœ í›„ë³´ ìˆ˜: {len(candidates)}ê°œ")
            print(f"ğŸ¯ ì„ íƒëœ í…ìŠ¤íŠ¸:")
            print(f"   {selected_text[:300]}...")
            
            print(f"\n" + "=" * 80)
            print("ğŸ”„ ë‹¨ê³„ 3: ì–´íœ˜ ìˆ˜ì • (í•„ìš”ì‹œ)")
            print("=" * 80)
            
            # 3ë‹¨ê³„: ì–´íœ˜ ìˆ˜ì • (í•„ìš”ì‹œ)
            # TODO: ì–´íœ˜ ìˆ˜ì • ë¡œì§ ì¶”ê°€ ì˜ˆì •
            print("ğŸ“š ì–´íœ˜ ìˆ˜ì •ì€ í˜„ì¬ êµ¬í˜„ ì¤‘ì…ë‹ˆë‹¤.")
            
            final_text = selected_text  # í˜„ì¬ëŠ” êµ¬ë¬¸ ìˆ˜ì • ê²°ê³¼ë¥¼ ìµœì¢… ê²°ê³¼ë¡œ ì‚¬ìš©
            
            print(f"\n" + "=" * 80)
            print("ğŸŠ ìµœì¢… ê²°ê³¼")
            print("=" * 80)
            
            total_time = time.time() - start_time
            
            # ê²°ê³¼ ë¹„êµí‘œ
            # print(f"ğŸ“Š ì§€í‘œ ë¹„êµ:")
            # print(f"   ì§€í‘œ                    | ì›ë³¸        | ìˆ˜ì • í›„     | ëª©í‘œ         | ìƒíƒœ")
            # print(f"   ----------------------- | ----------- | ----------- | ------------ | ----")
            # print(f"   í‰ê·  ë¬¸ì¥ ê¸¸ì´          | {original_metrics.AVG_SENTENCE_LENGTH:8.3f}    | {final_metrics.AVG_SENTENCE_LENGTH:8.3f}    | {master.AVG_SENTENCE_LENGTH:8.3f}       | {'âœ…' if final_evaluation.syntax_pass == 'PASS' else 'âŒ'}")
            # print(f"   ë‚´í¬ì ˆ ë¹„ìœ¨             | {original_metrics.All_Embedded_Clauses_Ratio:8.3f}    | {final_metrics.All_Embedded_Clauses_Ratio:8.3f}    | {master.All_Embedded_Clauses_Ratio:8.3f}       | {'âœ…' if final_evaluation.syntax_pass == 'PASS' else 'âŒ'}")
            # print(f"   A1A2 ì–´íœ˜ ë¹„ìœ¨         | {original_metrics.CEFR_NVJD_A1A2_lemma_ratio:8.3f}    | {final_metrics.CEFR_NVJD_A1A2_lemma_ratio:8.3f}    | {master.CEFR_NVJD_A1A2_lemma_ratio:8.3f}       | {'âœ…' if final_evaluation.lexical_pass == 'PASS' else 'âŒ'}")
            
            print(f"\nğŸ“ˆ ìµœì¢… í‰ê°€:")
            print(f"   ğŸ”§ êµ¬ë¬¸ í†µê³¼: {final_evaluation.syntax_pass}")
            print(f"   ğŸ“– ì–´íœ˜ í†µê³¼: {final_evaluation.lexical_pass}")
            
            print(f"\nâ±ï¸ ì†Œìš” ì‹œê°„:")
            print(f"   - ì›ë³¸ ë¶„ì„: {analysis_time:.2f}ì´ˆ")
            print(f"   - êµ¬ë¬¸ ìˆ˜ì •: {syntax_time:.2f}ì´ˆ")
            print(f"   - ì „ì²´: {total_time:.2f}ì´ˆ")
            
            print(f"\nğŸ“ ìµœì¢… í…ìŠ¤íŠ¸:")
            print(f"   {selected_text}")
            
            # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
            if final_evaluation.syntax_pass == "PASS":
                print(f"\nğŸ‰ êµ¬ë¬¸ ìˆ˜ì • ì„±ê³µ! ëª©í‘œ ì§€í‘œë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!")
            else:
                print(f"\nâš ï¸ êµ¬ë¬¸ ìˆ˜ì • ë¯¸ì™„ë£Œ. ì¶”ê°€ ìˆ˜ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            syntax_time = time.time() - syntax_start_time
            print(f"âŒ êµ¬ë¬¸ ìˆ˜ì • ì‹¤íŒ¨ (ì†Œìš” ì‹œê°„: {syntax_time:.2f}ì´ˆ)")
            print(f"   ì˜¤ë¥˜: {str(e)}")
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_full_syntax_pipeline()) 