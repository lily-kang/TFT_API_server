from typing import Dict, Any
from models.internal import MetricsData
from utils.exceptions import MetricsExtractionError
from utils.logging import logger
import json


class MetricsExtractor:
    """ë¶„ì„ ê²°ê³¼ì—ì„œ ì§€í‘œë¥¼ ì¶”ì¶œí•˜ëŠ” í´ë˜ìŠ¤"""
    
    def extract(self, raw_analysis: Dict[str, Any]) -> MetricsData:
        """
        ì™¸ë¶€ ë¶„ì„ê¸°ì˜ ì›ì‹œ ê²°ê³¼ì—ì„œ í•„ìš”í•œ ì§€í‘œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            raw_analysis: ì™¸ë¶€ ë¶„ì„ê¸° API ì‘ë‹µ
            
        Returns:
            ì¶”ì¶œëœ ì§€í‘œ ë°ì´í„°
            
        Raises:
            MetricsExtractionError: ì§€í‘œ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        
        try:
            logger.info("="*60)
            logger.info("ğŸ“Š ë¶„ì„ê¸° API ì‘ë‹µ ìƒì„¸ ë¡œê¹… ì‹œì‘")
            logger.info("="*60)
            
            # ì „ì²´ ì‘ë‹µ êµ¬ì¡° ë¡œê¹…
            # logger.info(f"ğŸ” ì „ì²´ ì‘ë‹µ í‚¤: {list(raw_analysis.keys())}")
            
            # ì‹¤ì œ API ì‘ë‹µ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
            data = raw_analysis.get("data", {})
            # logger.info(f"ğŸ“‹ data í‚¤: {list(data.keys())}")
            
            text_statistics = data.get("text_statistics", {})
            # logger.info(f"ğŸ“ˆ text_statistics í‚¤: {list(text_statistics.keys())}")
            
            # í…Œì´ë¸” ì¶”ì¶œ
            basic_overview = text_statistics.get("table_01_basic_overview", {})
            table_02 = text_statistics.get("table_02_detailed_tokens", {})
            syntax_analysis = text_statistics.get("table_10_syntax_analysis", {})
            table_11 = text_statistics.get("table_11_lemma_metrics", {})
            table_09 = text_statistics.get("table_09_pos_distribution", {})
            
            # 1. í‰ê·  ë¬¸ì¥ ê¸¸ì´
            avg_sentence_length = basic_overview.get("avg_sentence_length", 0.0)
            sentence_count = basic_overview.get("sentence_count", 1)
            logger.info(f"âœ… avg_sentence_length: {avg_sentence_length}")
            logger.info(f"âœ… sentence_count: {sentence_count}")
            
            # lexical_tokens ì¶”ì¶œ (t2 í…Œì´ë¸”ì—ì„œ)
            lexical_tokens = table_02.get("lexical_tokens", 0)
            logger.info(f"âœ… lexical_tokens: {lexical_tokens}")
            
            
            content_lemmas = table_02.get("content_lemmas", 0)
            propn_lemma_count = table_09.get("propn_lemma_count", 0)
            cefr_a1_count = table_11.get("cefr_a1_NVJD_lemma_count", 0)
            cefr_a2_count = table_11.get("cefr_a2_NVJD_lemma_count", 0)
            logger.info(f"ğŸ“Š content_lemmas: {content_lemmas}, propn_count: {propn_lemma_count}")
            logger.info(f"ğŸ“Š A1_count: {cefr_a1_count}, A2_count: {cefr_a2_count}")
            
            # 2. ë‚´í¬ì ˆ ë¹„ìœ¨ ì¶”ì¶œ

            adverbial_sentences = syntax_analysis.get("adverbial_clause_sentences", 0)
            coordinate_sentences = syntax_analysis.get("coordinate_clause_sentences", 0)
            nominal_sentences = syntax_analysis.get("nominal_clause_sentences", 0)
            relative_sentences = syntax_analysis.get("relative_clause_sentences", 0)
            
            total_clause_sentences = adverbial_sentences + coordinate_sentences + nominal_sentences + relative_sentences
            all_embedded_clauses_ratio = total_clause_sentences / sentence_count if sentence_count > 0 else 0.0
            
            logger.info(f"ğŸ“ˆ ì´ ì ˆ ë¬¸ì¥ ìˆ˜: {total_clause_sentences}")
            logger.info(f"ğŸ“ˆ ì „ì²´ ë¬¸ì¥ ìˆ˜: {sentence_count}")
            logger.info(f"âœ… All_Embedded_Clauses_Ratio: {all_embedded_clauses_ratio}")
            
            # 3. CEFR A1A2 ì–´íœ˜ ë¹„ìœ¨
            logger.info("\n" + "="*40)
            logger.info("ğŸ“š 3. CEFR_NVJD_lemma_A1A2 ì–´íœ˜ ë¹„ìœ¨")
            logger.info("="*40)
            
            
            # logger.info(f"ğŸ” table_11_lemma_metrics ì „ì²´ ë‚´ìš©:")
            # logger.info(json.dumps(lemma_metrics, indent=2, ensure_ascii=False))
            
            cefr_a1_ratio = table_11.get("cefr_a1_NVJD_lemma_ratio", 0.0)
            cefr_a2_ratio = table_11.get("cefr_a2_NVJD_lemma_ratio", 0.0)
            cefr_a1a2_ratio = cefr_a1_ratio + cefr_a2_ratio
            
            # logger.info(f"ğŸ“Š cefr_a1_NVJD_lemma_ratio: {cefr_a1_ratio}")
            # logger.info(f"ğŸ“Š cefr_a2_NVJD_lemma_ratio: {cefr_a2_ratio}")
            logger.info(f"âœ… CEFR_NVJD_A1A2_lemma_ratio: {cefr_a1a2_ratio}")
            
            # ìµœì¢… ê²°ê³¼
            extracted = MetricsData(
                AVG_SENTENCE_LENGTH=round(float(avg_sentence_length), 3),
                All_Embedded_Clauses_Ratio=round(float(all_embedded_clauses_ratio), 3),
                CEFR_NVJD_A1A2_lemma_ratio=round(float(cefr_a1a2_ratio), 3)
            )
            
            logger.info("\n" + "="*60)
            logger.info("ğŸ¯ ìµœì¢… ì¶”ì¶œëœ ì§€í‘œ")
            logger.info("="*60)
            logger.info(f"âœ… AVG_SENTENCE_LENGTH: {extracted.AVG_SENTENCE_LENGTH:.3f}")
            logger.info(f"âœ… All_Embedded_Clauses_Ratio: {extracted.All_Embedded_Clauses_Ratio:.3f}")
            logger.info(f"âœ… CEFR_NVJD_A1A2_lemma_ratio: {extracted.CEFR_NVJD_A1A2_lemma_ratio:.3f}")
            logger.info("="*60)
            
            return extracted
            
        except Exception as e:
            logger.error(f"ì§€í‘œ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
            raise MetricsExtractionError(f"ì§€í‘œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    def format_detailed_result(self, metrics: MetricsData, evaluation_result: Dict[str, Dict]) -> str:
        """
        ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
        
        Args:
            metrics: ì¶”ì¶œëœ ì§€í‘œ ë°ì´í„°
            evaluation_result: í‰ê°€ ê²°ê³¼ (ì§€í‘œë³„ ìƒì„¸ ì •ë³´ í¬í•¨)
            
        Returns:
            í¬ë§·íŒ…ëœ ìƒì„¸ ê²°ê³¼ ë¬¸ìì—´
        """
        result_lines = []
        
        for metric_name, detail in evaluation_result.items():
            if metric_name in ["syntax_pass", "lexical_pass"]:
                continue
                
            current_value = getattr(metrics, metric_name, None)
            if current_value is None:
                continue
                
            min_val = detail.get("min_value", 0)
            max_val = detail.get("max_value", 0)
            is_pass = detail.get("is_pass", False)
            status = "Pass" if is_pass else "Fail"
            
            line = f"{metric_name}: {current_value:.3f} vs [{min_val:.3f} ~ {max_val:.3f}] â†’ {status}"
            result_lines.append(line)
        
        return "\n".join(result_lines)


# ì „ì—­ ì§€í‘œ ì¶”ì¶œê¸° ì¸ìŠ¤í„´ìŠ¤
metrics_extractor = MetricsExtractor() 