"""í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¹Œë”"""

import math
import json
from typing import Dict, Any, Optional, List
from models.request import MasterMetrics, ToleranceAbs, ToleranceRatio
from config.syntax_revision_prompt import SYNTAX_USER_INPUT_TEMPLATE, SYNTAX_PROMPT_DECREASE, SYNTAX_PROMPT_INCREASE, CANDIDATE_SELECTION_PROMPT
from config.lexical_revision_prompt import Lexical_USER_INPUT_TEMPLATE, LEXICAL_FIXING_PROMPT_DECREASE, LEXICAL_FIXING_PROMPT_INCREASE
from utils.logging import logger

class PromptBuilder:
    """LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„± í´ë˜ìŠ¤"""
    
    def format_cefr_breakdown(self, cefr_breakdown: Any) -> str:
        """
        CEFR breakdown ê°ì²´ë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ ë³€í™˜
        
        Args:
            cefr_breakdown: CEFR breakdown ê°ì²´ (dict, list, ë˜ëŠ” ê¸°íƒ€ êµ¬ì¡°)
            
        Returns:
            í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©í•  ë¬¸ìì—´
        """
        try:
            if isinstance(cefr_breakdown, str):
                # ì´ë¯¸ ë¬¸ìì—´ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
                return cefr_breakdown
            elif isinstance(cefr_breakdown, dict):
                # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…
                formatted_lines = []
                for level, words in cefr_breakdown.items():
                    if isinstance(words, list):
                        word_list = ", ".join(words)
                        formatted_lines.append(f"{level}: {word_list}")
                    else:
                        formatted_lines.append(f"{level}: {words}")
                return "\n".join(formatted_lines)
            elif isinstance(cefr_breakdown, list):
                # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° JSON í˜•íƒœë¡œ ë³€í™˜
                return json.dumps(cefr_breakdown, indent=2, ensure_ascii=False)
            else:
                # ê¸°íƒ€ ê°ì²´ì¸ ê²½ìš° JSONìœ¼ë¡œ ë³€í™˜ ì‹œë„
                return json.dumps(cefr_breakdown, indent=2, ensure_ascii=False, default=str)
        except Exception as e:
            logger.warning(f"CEFR breakdown ë³€í™˜ ì‹¤íŒ¨: {str(e)}, ì›ë³¸ ë°˜í™˜")
            return str(cefr_breakdown)
    
    # def build_syntax_prompt(
    #     self,
    #     text: str,
    #     target_min: float,
    #     target_max: float,
    #     current_metrics: Dict[str, float],
    #     problematic_metric: str,
    #     num_modifications: int,
    #     referential_clauses: str = "",
    #     prompt_type: str = "increase"  # "increase" or "decrease"
    # ) -> str:
    #     """
    #     êµ¬ë¬¸ ìˆ˜ì •ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        
    #     Args:
    #         text: ìˆ˜ì •í•  í…ìŠ¤íŠ¸
    #         master: ë§ˆìŠ¤í„° ì§€í‘œ
    #         tolerance_abs: ì ˆëŒ€ê°’ í—ˆìš© ì˜¤ì°¨
    #         tolerance_ratio: ë¹„ìœ¨ í—ˆìš© ì˜¤ì°¨
    #         current_metrics: í˜„ì¬ ì§€í‘œê°’ë“¤
    #         problematic_metric: ë¬¸ì œê°€ ìˆëŠ” ì§€í‘œëª…
    #         num_modifications: ìˆ˜ì •í•  ë¬¸ì¥ ìˆ˜
    #         referential_clauses: ì°¸ì¡°ìš© ì ˆ ì •ë³´
    #         prompt_type: í”„ë¡¬í”„íŠ¸ íƒ€ì… ("increase" ë˜ëŠ” "decrease")
            
    #     Returns:
    #         êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    #     """
    #     try:
    #         # prompt_typeì— ë”°ë¼ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì„ íƒ
    #         if prompt_type == "increase":
    #             prompt = SYNTAX_PROMPT_INCREASE
    #             logger.info(f"ğŸ”º INCREASE í”„ë¡¬í”„íŠ¸ ì„ íƒë¨")
    #         elif prompt_type == "decrease":
    #             prompt = SYNTAX_PROMPT_DECREASE
    #             logger.info(f"ğŸ”» DECREASE í”„ë¡¬í”„íŠ¸ ì„ íƒë¨")
    #         else:
    #             prompt = SYNTAX_PROMPT_DECREASE  # ê¸°ë³¸ê°’
    #             logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” prompt_type: {prompt_type}, DECREASE ì‚¬ìš©")
            
            
    #         # í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ë§¤í•‘
    #         prompt_vars = {
    #             'var_Generated_Passage': text,
    #             'var_problematic_metric': problematic_metric,
    #             'var_num_modifications': str(num_modifications),
    #             'var_referential_clauses': referential_clauses or "No referential clauses provided.",
    #             'var_current_value_embedded_clauses_ratio' : current_metrics.get('all_embedded_clauses_ratio', 0),
    #             'var_target_range_embedded_clauses_ratio' : f"[{target_min:.3f} ~ {target_max:.3f}]",
    #         }
            
    #         # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ë³€ìˆ˜ ì‚½ì…
    #         for var_name, var_value in prompt_vars.items():
    #             prompt = prompt.replace(f"{{{var_name}}}", str(var_value))
            
    #         logger.info(f"êµ¬ë¬¸ ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ (ë¬¸ì œ ì§€í‘œ: {problematic_metric}, ìˆ˜ì • ìˆ˜: {num_modifications}, íƒ€ì…: {prompt_type})")
    #         return prompt
            
    #     except Exception as e:
    #         logger.error(f"êµ¬ë¬¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    #         raise
    
    def build_syntax_prompt(
        self,
        text: str,
        avg_target_min: float,
        avg_target_max: float,
        clause_target_min: float,
        clause_target_max: float,
        current_metrics: Dict[str, float],
        problematic_metric: str,
        num_modifications: int,
        referential_clauses: str = "",
        prompt_type: str = "increase"
    ) -> List[Dict[str, str]]:
        """
        êµ¬ë¬¸ ìˆ˜ì •ìš© prompt (ì‹œìŠ¤í…œ+ìœ ì €) êµ¬ì„±
        """
        try:
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
            if prompt_type == "increase":
                system_prompt = SYNTAX_PROMPT_INCREASE
            elif prompt_type == "decrease":
                system_prompt = SYNTAX_PROMPT_DECREASE
            else:
                system_prompt = SYNTAX_PROMPT_DECREASE

            # ë©”ì‹œì§€ ë³€ìˆ˜ ì¤€ë¹„ - ê° ì§€í‘œë³„ë¡œ ê°œë³„ í‘œì‹œ
            avg_current = current_metrics.get('avg_sentence_length', 0)
            clause_current = current_metrics.get('all_embedded_clauses_ratio', 0)
            
            current_and_target_values = f"""
            - average sentence length
            current value: {avg_current:.3f} target range: [{avg_target_min:.3f} ~ {avg_target_max:.3f}]
            - embedded clause ratio
            current value: {clause_current:.3f} target range: [{clause_target_min:.3f} ~ {clause_target_max:.3f}]
            """

            user_vars = {
                'var_Generated_Passage': text,
                'var_problematic_metric': problematic_metric,
                'var_num_modifications': str(num_modifications),
                'var_referential_clauses': referential_clauses or "No referential clauses provided.",
                'var_current_values': current_and_target_values
            }

            user_prompt = SYNTAX_USER_INPUT_TEMPLATE
            for var_name, var_value in user_vars.items():
                user_prompt = user_prompt.replace(f"{{{var_name}}}", str(var_value))
            
            return [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ]
        except Exception as e:
            logger.error(f"êµ¬ë¬¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    # def build_lexical_prompt(
    #     self,
    #     text: str,
    #     master: MasterMetrics,
    #     tolerance_ratio: ToleranceRatio,
    #     current_metrics: Dict[str, float],
        
    #     # prompt_type: str,  # "INCREASE" or "DECREASE"
    #     num_modifications: int = 3
    # ) -> str:
    #     """
    #     ì–´íœ˜ ìˆ˜ì •ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        
    #     Args:
    #         text: ìˆ˜ì •í•  í…ìŠ¤íŠ¸
    #         master: ë§ˆìŠ¤í„° ì§€í‘œ
    #         tolerance_ratio: ë¹„ìœ¨ í—ˆìš© ì˜¤ì°¨
    #         current_metrics: í˜„ì¬ ì§€í‘œê°’ë“¤
    #         cefr_breakdown: CEFR ì–´íœ˜ ë¶„ì„ ê²°ê³¼
    #         target_level: ëª©í‘œ ì–´íœ˜ ë ˆë²¨ (A1/A2 ë˜ëŠ” B1/B2)
    #         prompt_type: í”„ë¡¬í”„íŠ¸ íƒ€ì… ("INCREASE" ë˜ëŠ” "DECREASE")
    #         num_modifications: ìˆ˜ì •í•  ì–´íœ˜ ê°œìˆ˜
            
    #     Returns:
    #         êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    #     """
    #     try:
    #         # CEFR breakdown ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
    #         cefr_breakdown_str = self.format_cefr_breakdown(cefr_breakdown) if cefr_breakdown else ""
            
    #         # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„ íƒ
    #         if prompt_type == "DECREASE":
    #             # A1A2 ë¹„ìœ¨ì„ ë‚®ì¶°ì•¼ í•¨ (A1/A2 â†’ B1/B2)
    #             template = LEXICAL_FIXING_PROMPT_DECREASE
    #             logger.info("DECREASE í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„ íƒ (A1/A2 â†’ B1/B2)")
    #         elif prompt_type == "INCREASE":
    #             # A1A2 ë¹„ìœ¨ì„ ë†’ì—¬ì•¼ í•¨ (B1+ â†’ A1/A2)
    #             template = LEXICAL_FIXING_PROMPT_INCREASE
    #             logger.info("INCREASE í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„ íƒ (B1+ â†’ A1/A2)")
    #         else:
    #             raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” prompt_type: {prompt_type}. 'INCREASE' ë˜ëŠ” 'DECREASE'ì—¬ì•¼ í•©ë‹ˆë‹¤.")
            
    #         # í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ë§¤í•‘ (í…œí”Œë¦¿ì— ë§ì¶˜ ë³€ìˆ˜ëª… ì‚¬ìš©)
    #         prompt_vars = {
    #             'var_generated_passage': text,
    #             'var_cefr_breakdown': cefr_breakdown_str,
    #             'var_num_modifications': str(num_modifications),
    #             'var_target_level': target_level
    #         }
            
    #         # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ë³€ìˆ˜ ì‚½ì…
    #         prompt = template
    #         for var_name, var_value in prompt_vars.items():
    #             prompt = prompt.replace(f"${{{var_name}}}", str(var_value))
            
    #         logger.info(f"ì–´íœ˜ ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ({prompt_type})")
    #         return prompt
            
    #     except Exception as e:
    #         logger.error(f"ì–´íœ˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    #         raise
    
    def build_selection_prompt(
        self,
        candidates: List[str]
    ) -> str:
        """
        í›„ë³´ ì„ íƒìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ë²”ìš©)
        
        Args:
            candidates: í›„ë³´ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        try:
            if not candidates:
                raise ValueError("í›„ë³´ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            
            # í›„ë³´ ê°œìˆ˜ì— ë”°ë¼ ë™ì ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            num_candidates = len(candidates)
            
            # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
            base_prompt = """You are a precise text evaluator selecting the single best revised text from a list.

### Candidates"""
            
            # í›„ë³´ë“¤ ì¶”ê°€
            for i, candidate in enumerate(candidates, 1):
                base_prompt += f"\ncandidate_{i}: {candidate}"
            
            # í‰ê°€ ê¸°ì¤€ ì¶”ê°€
            base_prompt += """

### Evaluation Criteria (Strict Order):
1. **Foundational Correctness (Pass/Fail):** A candidate MUST be grammatically perfect AND perfectly preserve the original meaning. Any candidate that fails on either of these points is INSTANTLY DISQUALIFIED.
2. **Naturalness and Readability:** Among the candidates that pass Rule #1, the one that is most fluent and natural is better.
3. **Tie-Breaker:** If multiple candidates are equally good, choose the one that integrates its changes most elegantly.

### Response Format:
Respond ONLY with the number of the best candidate (1 to {num_candidates}).

Examples:"""
            
            # ì˜ˆì‹œ ì¶”ê°€
            for i in range(1, min(num_candidates + 1, 4)):  # ìµœëŒ€ 3ê°œ ì˜ˆì‹œê¹Œì§€ë§Œ
                base_prompt += f"\n- If candidate {i} is best: \"{i}\""
            
            if num_candidates > 3:
                base_prompt += f"\n- If candidate {num_candidates} is best: \"{num_candidates}\""
            
            base_prompt += f"""

Do not include any explanation, JSON, or additional text. Just the number between 1 and {num_candidates}."""
            
            logger.info(f"í›„ë³´ ì„ íƒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ({num_candidates}ê°œ í›„ë³´)")
            return base_prompt
            
        except Exception as e:
            logger.error(f"ì„ íƒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    def determine_problematic_metric(
        self,
        current_metrics: Dict[str, float],
        master: MasterMetrics,
        tolerance_abs: ToleranceAbs,
        tolerance_ratio: ToleranceRatio
    ) -> Optional[str]:
        """
        ë¬¸ì œê°€ ìˆëŠ” ì§€í‘œ ê²°ì •
        
        Args:
            current_metrics: í˜„ì¬ ì§€í‘œê°’ë“¤
            master: ë§ˆìŠ¤í„° ì§€í‘œ
            tolerance_abs: ì ˆëŒ€ê°’ í—ˆìš© ì˜¤ì°¨
            tolerance_ratio: ë¹„ìœ¨ í—ˆìš© ì˜¤ì°¨
            
        Returns:
            ë¬¸ì œê°€ ìˆëŠ” ì§€í‘œëª… ë˜ëŠ” None
        """
        try:
            # í‰ê·  ë¬¸ì¥ ê¸¸ì´ í™•ì¸
            avg_length = current_metrics.get('avg_sentence_length', 0)
            length_min = master.AVG_SENTENCE_LENGTH - tolerance_abs.AVG_SENTENCE_LENGTH
            length_max = master.AVG_SENTENCE_LENGTH + tolerance_abs.AVG_SENTENCE_LENGTH
            
            # ë‚´í¬ì ˆ ë¹„ìœ¨ í™•ì¸
            clause_ratio = current_metrics.get('embedded_clauses_ratio', 0)
            # clause_tolerance = master.All_Embedded_Clauses_Ratio * tolerance_ratio.All_Embedded_Clauses_Ratio
            clause_min = master.All_Embedded_Clauses_Ratio - tolerance_ratio.All_Embedded_Clauses_Ratio
            clause_max = master.All_Embedded_Clauses_Ratio + tolerance_ratio.All_Embedded_Clauses_Ratio
            
            # ìš°ì„ ìˆœìœ„: ë‚´í¬ì ˆ ë¹„ìœ¨ > í‰ê·  ë¬¸ì¥ ê¸¸ì´
            if not (clause_min <= clause_ratio <= clause_max):
                return "all_embedded_clauses_ratio"
            elif not (length_min <= avg_length <= length_max):
                return "avg_sentence_length"
            
            return None
            
        except Exception as e:
            logger.error(f"ë¬¸ì œ ì§€í‘œ ê²°ì • ì‹¤íŒ¨: {str(e)}")
            return None
    
    def calculate_modification_count(
        self,
        # text: str,
        problematic_metric: str,
        current_value: float,
        target_min: float,
        target_max: float,
        analysis_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        ìˆ˜ì •í•  ë¬¸ì¥ ìˆ˜ì™€ í”„ë¡¬í”„íŠ¸ íƒ€ì… ê³„ì‚° (ë™ì  ê³„ì‚°)
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            problematic_metric: ë¬¸ì œ ì§€í‘œëª…
            current_value: í˜„ì¬ ê°’
            target_min: ëª©í‘œ ìµœì†Œê°’
            target_max: ëª©í‘œ ìµœëŒ€ê°’
            analysis_result: ë¶„ì„ ê²°ê³¼ (sentence_count, lexical_tokens, clause ì •ë³´ ë“±)
            
        Returns:
            {'num_modifications': int, 'prompt_type': str} ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ë¶„ì„ ê²°ê³¼ì—ì„œ í•„ìš”í•œ ê°’ë“¤ ì¶”ì¶œ
            sentence_count = analysis_result.get('sentence_count', 0)
            lexical_tokens = analysis_result.get('lexical_tokens', 0)

            # ë³µë¬¸ ë¬¸ì¥ ìˆ˜ ì´í•© ê³„ì‚°

            total_clause_sentences = analysis_result.get('total_clause_sentences', 0)

            logger.info(f"ğŸ” ìˆ˜ì • ë¬¸ì¥ ìˆ˜ ê³„ì‚° ìƒì„¸:")
            logger.info(f"  - sentence_count: {sentence_count}")
            logger.info(f"  - lexical_tokens: {lexical_tokens}")
            logger.info(f"  - total_clause_sentences: {total_clause_sentences}")
            logger.info(f"  - problematic_metric: {problematic_metric}")
            logger.info(f"  - current_value: {current_value:.3f}")
            logger.info(f"  - target_min: {target_min:.3f}, target_max: {target_max:.3f}")
            
            # prompt_type ê²°ì •
            if current_value < target_min:
                prompt_type = "increase"
                logger.info(f"ğŸ”º í˜„ì¬ê°’({current_value:.3f}) < ìµœì†Œê°’({target_min:.3f}) â†’ INCREASE í”„ë¡¬í”„íŠ¸ ì„ íƒ")
            elif current_value > target_max:
                prompt_type = "decrease"
                logger.info(f"ğŸ”» í˜„ì¬ê°’({current_value:.3f}) > ìµœëŒ€ê°’({target_max:.3f}) â†’ DECREASE í”„ë¡¬í”„íŠ¸ ì„ íƒ")
            else:
                prompt_type = "decrease"  # ë²”ìœ„ ë‚´ì— ìˆìœ¼ë©´ ê¸°ë³¸ê°’
                logger.info(f"âšª í˜„ì¬ê°’ì´ ë²”ìœ„ ë‚´ì— ìˆìŒ â†’ ê¸°ë³¸ DECREASE í”„ë¡¬í”„íŠ¸ ì„ íƒ")
            
            # í‰ê·  ë¬¸ì¥ ê¸¸ì´ë¥¼ ìˆ˜ì •í•  ê²½ìš° 
            if 'length' in problematic_metric.lower():
                logger.info(f"ğŸ“ í‰ê·  ë¬¸ì¥ ê¸¸ì´ ê³„ì‚° ì‹œì‘")
                if current_value > target_max:
                    # í‰ê·  ë¬¸ì¥ ê¸¸ì´ê°€ ê¸°ì¤€ë³´ë‹¤ í¼ â†’ ë¬¸ì¥ ìˆ˜ decrease
                    upper_bound = target_max
                    num_modifications = math.ceil((lexical_tokens / upper_bound) - sentence_count)
                    logger.info(f"  - í˜„ì¬ê°’({current_value:.3f}) > ìµœëŒ€ê°’({target_max:.3f})")
                    logger.info(f"  - ê³„ì‚°: ceil(({lexical_tokens} / {upper_bound:.3f}) - {sentence_count}) = {num_modifications}")
                else:
                    # í‰ê·  ë¬¸ì¥ ê¸¸ì´ê°€ ê¸°ì¤€ë³´ë‹¤ ì‘ìŒ â†’ ë¬¸ì¥ ìˆ˜ increase
                    lower_bound = target_min
                    num_modifications = math.floor(sentence_count - (lexical_tokens / lower_bound))
                    logger.info(f"  - í˜„ì¬ê°’({current_value:.3f}) < ìµœì†Œê°’({target_min:.3f})")
                    logger.info(f"  - ê³„ì‚°: floor({sentence_count} - ({lexical_tokens} / {lower_bound:.3f})) = {num_modifications}")

            # ë³µë¬¸ ë¹„ìœ¨ì„ ìˆ˜ì •í•  ê²½ìš°
            elif 'clause' in problematic_metric.lower() or 'embedded' in problematic_metric.lower():
                logger.info(f"ğŸ”— ë³µë¬¸ ë¹„ìœ¨ ê³„ì‚° ì‹œì‘")
                if current_value > target_max:
                    # ë³µë¬¸ ë¹„ìœ¨ì´ ê¸°ì¤€ë³´ë‹¤ í¼ â†’ ë³µë¬¸ ì¤„ì—¬ì•¼ í•¨
                    target_ratio_upper = target_max
                    num_modifications = math.ceil(
                        (total_clause_sentences - (target_ratio_upper * sentence_count)) / 
                        (1 + target_ratio_upper)
                    )
                    logger.info(f"  - í˜„ì¬ê°’({current_value:.3f}) > ìµœëŒ€ê°’({target_max:.3f})")
                    logger.info(f"  - ê³„ì‚°: ceil(({total_clause_sentences} - ({target_ratio_upper:.3f} * {sentence_count})) / (1 + {target_ratio_upper:.3f})) = {num_modifications}")
                else:
                    # ë³µë¬¸ ë¹„ìœ¨ì´ ê¸°ì¤€ë³´ë‹¤ ì‘ìŒ â†’ ë³µë¬¸ ëŠ˜ë ¤ì•¼ í•¨
                    target_ratio_lower = target_min
                    num_modifications = math.ceil(
                        ((target_ratio_lower * sentence_count) - total_clause_sentences) / 
                        (1 + target_ratio_lower)
                    )
                    logger.info(f"  - í˜„ì¬ê°’({current_value:.3f}) < ìµœì†Œê°’({target_min:.3f})")
                    logger.info(f"  - ê³„ì‚°: ceil((({target_ratio_lower:.3f} * {sentence_count}) - {total_clause_sentences}) / (1 + {target_ratio_lower:.3f})) = {num_modifications}")

            else:
                # ì§€ì •ë˜ì§€ ì•Šì€ ë©”íŠ¸ë¦­ â†’ ê¸°ë³¸ê°’
                num_modifications = 3
                logger.info(f"âš ï¸  ì§€ì •ë˜ì§€ ì•Šì€ ë©”íŠ¸ë¦­: {problematic_metric}, ê¸°ë³¸ê°’ 3 ì‚¬ìš©")
            

            result = {
                'num_modifications': num_modifications,
                'prompt_type': prompt_type
            }
            
            logger.info(f"âœ… ìµœì¢… ê²°ê³¼: {result}")
            return result

        except Exception as e:
            logger.error(f"ìˆ˜ì • ë¬¸ì¥ ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
            return {'num_modifications': 3, 'prompt_type': 'increase'}  # ê¸°ë³¸ê°’ ë°˜í™˜
    

    def calculate_lexical_modification_count_nvjd(
        self,
        current_ratio: float,
        nvjd_total_lemma_count: int,
        nvjd_a1a2_lemma_count: int,
        master,
        tolerance_ratio,
    ) -> Dict[str, object]:
        """NVJD ê¸°ë°˜ ì–´íœ˜ ìˆ˜ì • ë‹¨ì–´ ìˆ˜ ê³„ì‚° (ë¶„ì„ê¸° í˜¸ì¶œ ì—†ì´ ì‚¬ì „ ê³„ì‚°ê°’ ì‚¬ìš©)
        Returns dict: { num_modifications, direction, target_lower, target_upper, case }
        direction: "increase" | "decrease" | "none"
        """
        # ëª©í‘œ ë²”ìœ„ ê³„ì‚° (ì ˆëŒ€ê°’ Â± tolerance)
        target_lower = master.CEFR_NVJD_A1A2_lemma_ratio - tolerance_ratio.CEFR_NVJD_A1A2_lemma_ratio
        target_upper = master.CEFR_NVJD_A1A2_lemma_ratio + tolerance_ratio.CEFR_NVJD_A1A2_lemma_ratio

        # ê²½ê³„ ì²˜ë¦¬
        total = max(1, int(nvjd_total_lemma_count or 0))
        a1a2 = max(0, int(nvjd_a1a2_lemma_count or 0))
        cur = float(current_ratio)

        if target_lower <= cur <= target_upper:
            return {
                "num_modifications": 0,
                "direction": "none",
                "target_lower": target_lower,
                "target_upper": target_upper,
                "case": "within",
            }

        if cur < target_lower:
            need = (target_lower * total) - a1a2
            mods = int(math.ceil(need))
            return {
                "num_modifications": mods,
                "direction": "increase",
                "target_lower": target_lower,
                "target_upper": target_upper,
                "case": "below",
            }

        # cur > target_upper
        allow = target_upper * total
        need_remove = a1a2 - allow
        mods = int(math.ceil(need_remove))
        return {
            "num_modifications": mods,
            "direction": "decrease",
            "target_lower": target_lower,
            "target_upper": target_upper,
            "case": "above",
        }
##___________________________________#
    def build_lexical_prompt(
        self,
        text: str,
        current_cefr_ratio: float,
        target_min: float,
        target_max: float,
        num_modifications: int,
        direction: str,
        cefr_breakdown: Optional[Dict[str, Any]] = None
    ) -> list:
        """ì–´íœ˜ ìˆ˜ì • í”„ë¡¬í”„íŠ¸ êµ¬ì„± (Lexical_USER_INPUT_TEMPLATE ì‚¬ìš©)"""
        system_prompt = LEXICAL_FIXING_PROMPT_INCREASE if direction == "increase" else LEXICAL_FIXING_PROMPT_DECREASE
        formatted_text_json = self._format_lexical_text_with_metrics(text, current_cefr_ratio, target_min, target_max)
        processed_profile = self._generate_vocab_profile(cefr_breakdown or {}, direction)
        target_level = "A1/A2" if direction == "increase" else "B1/B2"

        user_prompt = Lexical_USER_INPUT_TEMPLATE.format(
            var_originalText=text,
            var_formattedTextJson=formatted_text_json,
            var_processedProfile=processed_profile,
            var_totalModifications=num_modifications,
            var_targetLevel=target_level
        )
        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

    def _format_lexical_text_with_metrics(
        self,
        text: str,
        current_ratio: float,
        target_min: float,
        target_max: float
    ) -> str:
        import json as _json
        # ê°„ë‹¨í•œ ë¬¸ì¥ ë¶„í• 
        sentences = text.split('. ')
        if len(sentences) > 1:
            sentences = [s + '.' if not s.endswith('.') else s for s in sentences[:-1]] + [sentences[-1]]
        formatted_sentences = [{"sentence_number": i, "text": s.strip()} for i, s in enumerate(sentences, 1)]
        metrics_info = f"""
- cefr_a1+a2_NVJD_lemma_ratio:
- current value: {current_ratio:.1%}
- target range: {target_min:.1%}~{target_max:.1%}
"""
        return f"""
## Sentences (JSON format):
{_json.dumps(formatted_sentences, ensure_ascii=False, indent=2)}

## Current Metrics:
{metrics_info}
"""

    def _generate_vocab_profile(self, cefr_breakdown: Dict[str, Any], direction: str) -> str:
        """cefr_breakdownì„ direction ê¸°ì¤€ìœ¼ë¡œ ì •ì œí•˜ì—¬ ì¶œë ¥ ë¬¸ìì—´ ìƒì„±
        - decrease: B1+ (b1,b2,c1,c2)ë§Œ í‘œì‹œ
        - increase: A1/A2/B1ë§Œ í‘œì‹œ
        """
        try:
            buckets_increase = ["a1", "a2", "b1"]
            buckets_decrease = ["b1", "b2", "c1", "c2"]
            selected = buckets_increase if direction == "increase" else buckets_decrease

            lines: List[str] = []
            for key in selected:
                slot = cefr_breakdown.get(key) or {}
                lemma_count = slot.get("lemma_count", 0)
                lemma_list = slot.get("lemma_list", []) or []
                lines.append(f"## {key.upper()} Lemmas (count={lemma_count})")
                if lemma_list:
                    lines.extend([f"- {lemma}" for lemma in lemma_list])
            else:
                lines.append("- (none)")
                lines.append("")
            return "\n".join(lines).strip()
        except Exception as e:
            logger.warning(f"vocab profile ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return ""

# ì „ì—­ í”„ë¡¬í”„íŠ¸ ë¹Œë” ì¸ìŠ¤í„´ìŠ¤
prompt_builder = PromptBuilder() 


if __name__ == "__main__":
    instance = PromptBuilder()
    instance.calculate_modification_count(
        problematic_metric="all_embedded_clauses_ratio",
        current_value=0.55,
        target_min=0.181,
        target_max=0.272,
        analysis_result={
            'sentence_count': 53,
            'lexical_tokens': 463,
            'total_clause_sentences': 12}
    )