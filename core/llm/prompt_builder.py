"""í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë¹Œë”"""

import math
import json
from typing import Dict, Any, Optional, List
from models.request import MasterMetrics, ToleranceAbs, ToleranceRatio
from config.prompts import SYNTAX_FIXING_PROMPT, LEXICAL_FIXING_PROMPT_DECREASE, LEXICAL_FIXING_PROMPT_INCREASE, CANDIDATE_SELECTION_PROMPT
from utils.logging import logger


class PromptBuilder:
    """LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„± í´ë˜ìŠ¤"""
    
    def format_cefr_breakdown(self, cefr_breakdown: Any) -> str:
        """
        CEFR breakdown ê°ì²´ë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ ë³€í™˜
        
        Args:
            cefr_breakdown: CEFR breakdown ê°ì²´ (dict, list, ë˜ëŠ” ê¸°íƒ€ êµ¬ì¡°)
            
        Returns:
            í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©í•  ë¬¸ìì—´
        """
        try:
            if isinstance(cefr_breakdown, str):
                # ì´ë¯¸ ë¬¸ìì—´ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
                return cefr_breakdown
            elif isinstance(cefr_breakdown, dict):
                # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…
                formatted_lines = []
                for level, words in cefr_breakdown.items():
                    if isinstance(words, list):
                        word_list = ", ".join(words)
                        formatted_lines.append(f"{level}: {word_list}")
                    else:
                        formatted_lines.append(f"{level}: {words}")
                return "\n".join(formatted_lines)
            elif isinstance(cefr_breakdown, list):
                # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° JSON í˜•íƒœë¡œ ë³€í™˜
                return json.dumps(cefr_breakdown, indent=2, ensure_ascii=False)
            else:
                # ê¸°íƒ€ ê°ì²´ì¸ ê²½ìš° JSONìœ¼ë¡œ ë³€í™˜ ì‹œë„
                return json.dumps(cefr_breakdown, indent=2, ensure_ascii=False, default=str)
        except Exception as e:
            logger.warning(f"CEFR breakdown ë³€í™˜ ì‹¤íŒ¨: {str(e)}, ì›ë³¸ ë°˜í™˜")
            return str(cefr_breakdown)
    
    def build_syntax_prompt(
        self,
        text: str,
        master: MasterMetrics,
        tolerance_abs: ToleranceAbs,
        tolerance_ratio: ToleranceRatio,
        current_metrics: Dict[str, float],
        problematic_metric: str,
        num_modifications: int,
        referential_clauses: str = ""
    ) -> str:
        """
        êµ¬ë¬¸ ìˆ˜ì •ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        
        Args:
            text: ìˆ˜ì •í•  í…ìŠ¤íŠ¸
            master: ë§ˆìŠ¤í„° ì§€í‘œ
            tolerance_abs: ì ˆëŒ€ê°’ í—ˆìš© ì˜¤ì°¨
            tolerance_ratio: ë¹„ìœ¨ í—ˆìš© ì˜¤ì°¨
            current_metrics: í˜„ì¬ ì§€í‘œê°’ë“¤
            problematic_metric: ë¬¸ì œê°€ ìˆëŠ” ì§€í‘œëª…
            num_modifications: ìˆ˜ì •í•  ë¬¸ì¥ ìˆ˜ (ê³ ì •ê°’ 3 ì‚¬ìš©)
            referential_clauses: ì°¸ì¡°ìš© ì ˆ ì •ë³´
            
        Returns:
            êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        try:
            # ëª©í‘œ ë²”ìœ„ ê³„ì‚° - í•­ìƒ ë‘ ì§€í‘œ ëª¨ë‘ ê³„ì‚°
            # í‰ê·  ë¬¸ì¥ ê¸¸ì´ ëª©í‘œ ë²”ìœ„
            target_min_length = master.AVG_SENTENCE_LENGTH - tolerance_abs.AVG_SENTENCE_LENGTH
            target_max_length = master.AVG_SENTENCE_LENGTH + tolerance_abs.AVG_SENTENCE_LENGTH
            target_range_length = f"{target_min_length:.2f} - {target_max_length:.2f}"
            
            # ë‚´í¬ì ˆ ë¹„ìœ¨ ëª©í‘œ ë²”ìœ„
            clause_tolerance = master.All_Embedded_Clauses_Ratio * tolerance_ratio.All_Embedded_Clauses_Ratio
            target_min_clauses = master.All_Embedded_Clauses_Ratio - clause_tolerance
            target_max_clauses = master.All_Embedded_Clauses_Ratio + clause_tolerance
            target_range_clauses = f"{target_min_clauses:.3f} - {target_max_clauses:.3f}"
            
            # ê³ ì •ê°’ 3ìœ¼ë¡œ ì„¤ì • (ì‚¬ìš©ì ìš”ì²­)
            # fixed_num_modifications = 3
            
            # í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ë§¤í•‘
            prompt_vars = {
                'var_Generated_Passage': text,
                'var_problematic_metric': problematic_metric,
                'var_num_modifications': str(num_modifications),  
                'var_current_value_avg_sentence_length': f"{current_metrics.get('avg_sentence_length', 0):.2f}",
                'var_target_range_avg_sentence_length': target_range_length,
                'var_current_value_embedded_clauses_ratio': f"{current_metrics.get('embedded_clauses_ratio', 0):.3f}",
                'var_target_range_embedded_clauses_ratio': target_range_clauses,
                'var_referential_clauses': referential_clauses or "No referential clauses provided."
            }
            
            # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ë³€ìˆ˜ ì‚½ì…
            prompt = SYNTAX_FIXING_PROMPT
            for var_name, var_value in prompt_vars.items():
                prompt = prompt.replace(f"{{{var_name}}}", str(var_value))
            
            logger.info(f"êµ¬ë¬¸ ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ (ë¬¸ì œ ì§€í‘œ: {problematic_metric}, ìˆ˜ì • ìˆ˜: {num_modifications})")
            return prompt
            
        except Exception as e:
            logger.error(f"êµ¬ë¬¸ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    def build_lexical_prompt(
        self,
        text: str,
        master: MasterMetrics,
        tolerance_ratio: ToleranceRatio,
        current_metrics: Dict[str, float],
        cefr_breakdown: Any = None,
        # prompt_type: str,  # "INCREASE" or "DECREASE"
        num_modifications: int = 3
    ) -> str:
        """
        ì–´íœ˜ ìˆ˜ì •ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        
        Args:
            text: ìˆ˜ì •í•  í…ìŠ¤íŠ¸
            master: ë§ˆìŠ¤í„° ì§€í‘œ
            tolerance_ratio: ë¹„ìœ¨ í—ˆìš© ì˜¤ì°¨
            current_metrics: í˜„ì¬ ì§€í‘œê°’ë“¤
            cefr_breakdown: CEFR ì–´íœ˜ ë¶„ì„ ê²°ê³¼
            target_level: ëª©í‘œ ì–´íœ˜ ë ˆë²¨ (A1/A2 ë˜ëŠ” B1/B2)
            prompt_type: í”„ë¡¬í”„íŠ¸ íƒ€ì… ("INCREASE" ë˜ëŠ” "DECREASE")
            num_modifications: ìˆ˜ì •í•  ì–´íœ˜ ê°œìˆ˜
            
        Returns:
            êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        try:
            # CEFR breakdown ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            cefr_breakdown_str = self.format_cefr_breakdown(cefr_breakdown) if cefr_breakdown else ""
            
            # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„ íƒ
            if prompt_type == "DECREASE":
                # A1A2 ë¹„ìœ¨ì„ ë‚®ì¶°ì•¼ í•¨ (A1/A2 â†’ B1/B2)
                template = LEXICAL_FIXING_PROMPT_DECREASE
                logger.info("DECREASE í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„ íƒ (A1/A2 â†’ B1/B2)")
            elif prompt_type == "INCREASE":
                # A1A2 ë¹„ìœ¨ì„ ë†’ì—¬ì•¼ í•¨ (B1+ â†’ A1/A2)
                template = LEXICAL_FIXING_PROMPT_INCREASE
                logger.info("INCREASE í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„ íƒ (B1+ â†’ A1/A2)")
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” prompt_type: {prompt_type}. 'INCREASE' ë˜ëŠ” 'DECREASE'ì—¬ì•¼ í•©ë‹ˆë‹¤.")
            
            # í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ë§¤í•‘ (í…œí”Œë¦¿ì— ë§ì¶˜ ë³€ìˆ˜ëª… ì‚¬ìš©)
            prompt_vars = {
                'var_generated_passage': text,
                'var_cefr_breakdown': cefr_breakdown_str,
                'var_num_modifications': str(num_modifications),
                'var_target_level': target_level
            }
            
            # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ë³€ìˆ˜ ì‚½ì…
            prompt = template
            for var_name, var_value in prompt_vars.items():
                prompt = prompt.replace(f"${{{var_name}}}", str(var_value))
            
            logger.info(f"ì–´íœ˜ ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ({prompt_type})")
            return prompt
            
        except Exception as e:
            logger.error(f"ì–´íœ˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    def build_selection_prompt(
        self,
        candidates: List[str]
    ) -> str:
        """
        í›„ë³´ ì„ íƒìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ë²”ìš©)
        
        Args:
            candidates: í›„ë³´ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        try:
            if not candidates:
                raise ValueError("í›„ë³´ ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            
            # í›„ë³´ ê°œìˆ˜ì— ë”°ë¼ ë™ì ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±
            num_candidates = len(candidates)
            
            # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
            base_prompt = """You are a precise text evaluator selecting the single best revised text from a list.

### Candidates"""
            
            # í›„ë³´ë“¤ ì¶”ê°€
            for i, candidate in enumerate(candidates, 1):
                base_prompt += f"\ncandidate_{i}: {candidate}"
            
            # í‰ê°€ ê¸°ì¤€ ì¶”ê°€
            base_prompt += """

### Evaluation Criteria (Strict Order):
1. **Foundational Correctness (Pass/Fail):** A candidate MUST be grammatically perfect AND perfectly preserve the original meaning. Any candidate that fails on either of these points is INSTANTLY DISQUALIFIED.
2. **Naturalness and Readability:** Among the candidates that pass Rule #1, the one that is most fluent and natural is better.
3. **Tie-Breaker:** If multiple candidates are equally good, choose the one that integrates its changes most elegantly.

### Response Format:
Respond ONLY with the number of the best candidate (1 to {num_candidates}).

Examples:"""
            
            # ì˜ˆì‹œ ì¶”ê°€
            for i in range(1, min(num_candidates + 1, 4)):  # ìµœëŒ€ 3ê°œ ì˜ˆì‹œê¹Œì§€ë§Œ
                base_prompt += f"\n- If candidate {i} is best: \"{i}\""
            
            if num_candidates > 3:
                base_prompt += f"\n- If candidate {num_candidates} is best: \"{num_candidates}\""
            
            base_prompt += f"""

Do not include any explanation, JSON, or additional text. Just the number between 1 and {num_candidates}."""
            
            logger.info(f"í›„ë³´ ì„ íƒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ({num_candidates}ê°œ í›„ë³´)")
            return base_prompt
            
        except Exception as e:
            logger.error(f"ì„ íƒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    def determine_problematic_metric(
        self,
        current_metrics: Dict[str, float],
        master: MasterMetrics,
        tolerance_abs: ToleranceAbs,
        tolerance_ratio: ToleranceRatio
    ) -> Optional[str]:
        """
        ë¬¸ì œê°€ ìˆëŠ” ì§€í‘œ ê²°ì •
        
        Args:
            current_metrics: í˜„ì¬ ì§€í‘œê°’ë“¤
            master: ë§ˆìŠ¤í„° ì§€í‘œ
            tolerance_abs: ì ˆëŒ€ê°’ í—ˆìš© ì˜¤ì°¨
            tolerance_ratio: ë¹„ìœ¨ í—ˆìš© ì˜¤ì°¨
            
        Returns:
            ë¬¸ì œê°€ ìˆëŠ” ì§€í‘œëª… ë˜ëŠ” None
        """
        try:
            # í‰ê·  ë¬¸ì¥ ê¸¸ì´ í™•ì¸
            avg_length = current_metrics.get('avg_sentence_length', 0)
            length_min = master.AVG_SENTENCE_LENGTH - tolerance_abs.AVG_SENTENCE_LENGTH
            length_max = master.AVG_SENTENCE_LENGTH + tolerance_abs.AVG_SENTENCE_LENGTH
            
            # ë‚´í¬ì ˆ ë¹„ìœ¨ í™•ì¸
            clause_ratio = current_metrics.get('embedded_clauses_ratio', 0)
            clause_tolerance = master.All_Embedded_Clauses_Ratio * tolerance_ratio.All_Embedded_Clauses_Ratio
            clause_min = master.All_Embedded_Clauses_Ratio - clause_tolerance
            clause_max = master.All_Embedded_Clauses_Ratio + clause_tolerance
            
            # ìš°ì„ ìˆœìœ„: ë‚´í¬ì ˆ ë¹„ìœ¨ > í‰ê·  ë¬¸ì¥ ê¸¸ì´
            if not (clause_min <= clause_ratio <= clause_max):
                return "all_embedded_clauses_ratio"
            elif not (length_min <= avg_length <= length_max):
                return "avg_sentence_length"
            
            return None
            
        except Exception as e:
            logger.error(f"ë¬¸ì œ ì§€í‘œ ê²°ì • ì‹¤íŒ¨: {str(e)}")
            return None
    
    def calculate_modification_count(
        self,
        text: str,
        problematic_metric: str,
        current_value: float,
        target_min: float,
        target_max: float,
        analysis_result: Dict[str, Any]
    ) -> int:
        """
        ìˆ˜ì •í•  ë¬¸ì¥ ìˆ˜ ê³„ì‚° (ë™ì  ê³„ì‚°)
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            problematic_metric: ë¬¸ì œ ì§€í‘œëª…
            current_value: í˜„ì¬ ê°’
            target_min: ëª©í‘œ ìµœì†Œê°’
            target_max: ëª©í‘œ ìµœëŒ€ê°’
            analysis_result: ë¶„ì„ ê²°ê³¼ (sentence_count, lexical_tokens, clause ì •ë³´ ë“±)
            
        Returns:
            ìˆ˜ì •í•  ë¬¸ì¥ ìˆ˜
        """
        try:
            # ë¶„ì„ ê²°ê³¼ì—ì„œ í•„ìš”í•œ ê°’ë“¤ ì¶”ì¶œ
            sentence_count = analysis_result.get('sentence_count', 0)
            lexical_tokens = analysis_result.get('lexical_tokens', 0)

            # ë³µë¬¸ ë¬¸ì¥ ìˆ˜ ì´í•© ê³„ì‚°
            adverbial_clause_sentences = analysis_result.get('adverbial_clause_sentences', 0)
            coordinate_clause_sentences = analysis_result.get('coordinate_clause_sentences', 0)
            nominal_clause_sentences = analysis_result.get('nominal_clause_sentences', 0)
            relative_clause_sentences = analysis_result.get('relative_clause_sentences', 0)

            total_clause_sentences = (
                adverbial_clause_sentences + 
                coordinate_clause_sentences + 
                nominal_clause_sentences + 
                relative_clause_sentences
            )

            logger.info(f"ğŸ” ìˆ˜ì • ë¬¸ì¥ ìˆ˜ ê³„ì‚° ìƒì„¸:")
            logger.info(f"  - sentence_count: {sentence_count}")
            logger.info(f"  - lexical_tokens: {lexical_tokens}")
            logger.info(f"  - total_clause_sentences: {total_clause_sentences}")
            logger.info(f"  - problematic_metric: {problematic_metric}")
            logger.info(f"  - current_value: {current_value:.3f}")
            logger.info(f"  - target_min: {target_min:.3f}, target_max: {target_max:.3f}")

            # í‰ê·  ë¬¸ì¥ ê¸¸ì´ íŒë‹¨
            if 'length' in problematic_metric.lower():
                logger.info(f"ğŸ“ í‰ê·  ë¬¸ì¥ ê¸¸ì´ ê³„ì‚° ì‹œì‘")
                if current_value > target_max:
                    # í‰ê·  ë¬¸ì¥ ê¸¸ì´ê°€ ê¸°ì¤€ë³´ë‹¤ í¼ â†’ ë¬¸ì¥ ìˆ˜ ëŠ˜ë ¤ì•¼ í•¨
                    upper_bound = target_max
                    num_modifications = math.ceil((lexical_tokens / upper_bound) - sentence_count)
                    logger.info(f"  - í˜„ì¬ê°’({current_value:.3f}) > ìµœëŒ€ê°’({target_max:.3f})")
                    logger.info(f"  - ê³„ì‚°: ceil(({lexical_tokens} / {upper_bound:.3f}) - {sentence_count}) = {num_modifications}")
                else:
                    # í‰ê·  ë¬¸ì¥ ê¸¸ì´ê°€ ê¸°ì¤€ë³´ë‹¤ ì‘ìŒ â†’ ë¬¸ì¥ ìˆ˜ ì¤„ì—¬ì•¼ í•¨
                    lower_bound = target_min
                    num_modifications = math.floor(sentence_count - (lexical_tokens / lower_bound))
                    logger.info(f"  - í˜„ì¬ê°’({current_value:.3f}) < ìµœì†Œê°’({target_min:.3f})")
                    logger.info(f"  - ê³„ì‚°: floor({sentence_count} - ({lexical_tokens} / {lower_bound:.3f})) = {num_modifications}")

            # ë³µë¬¸ ë¹„ìœ¨ íŒë‹¨
            elif 'clause' in problematic_metric.lower() or 'embedded' in problematic_metric.lower():
                logger.info(f"ğŸ”— ë³µë¬¸ ë¹„ìœ¨ ê³„ì‚° ì‹œì‘")
                if current_value > target_max:
                    # ë³µë¬¸ ë¹„ìœ¨ì´ ê¸°ì¤€ë³´ë‹¤ í¼ â†’ ë³µë¬¸ ì¤„ì—¬ì•¼ í•¨
                    target_ratio_upper = target_max
                    num_modifications = math.ceil(
                        (total_clause_sentences - (target_ratio_upper * sentence_count)) / 
                        (1 + target_ratio_upper)
                    )
                    logger.info(f"  - í˜„ì¬ê°’({current_value:.3f}) > ìµœëŒ€ê°’({target_max:.3f})")
                    logger.info(f"  - ê³„ì‚°: ceil(({total_clause_sentences} - ({target_ratio_upper:.3f} * {sentence_count})) / (1 + {target_ratio_upper:.3f})) = {num_modifications}")
                else:
                    # ë³µë¬¸ ë¹„ìœ¨ì´ ê¸°ì¤€ë³´ë‹¤ ì‘ìŒ â†’ ë³µë¬¸ ëŠ˜ë ¤ì•¼ í•¨
                    target_ratio_lower = target_min
                    num_modifications = math.ceil(
                        ((target_ratio_lower * sentence_count) - total_clause_sentences) / 
                        (1 + target_ratio_lower)
                    )
                    logger.info(f"  - í˜„ì¬ê°’({current_value:.3f}) < ìµœì†Œê°’({target_min:.3f})")
                    logger.info(f"  - ê³„ì‚°: ceil((({target_ratio_lower:.3f} * {sentence_count}) - {total_clause_sentences}) / (1 + {target_ratio_lower:.3f})) = {num_modifications}")

            else:
                # ì§€ì •ë˜ì§€ ì•Šì€ ë©”íŠ¸ë¦­ â†’ ê¸°ë³¸ê°’
                num_modifications = 3
                logger.info(f"âš ï¸  ì§€ì •ë˜ì§€ ì•Šì€ ë©”íŠ¸ë¦­: {problematic_metric}, ê¸°ë³¸ê°’ 3 ì‚¬ìš©")

            logger.info(f"âœ… ìµœì¢… ìˆ˜ì • ë¬¸ì¥ ìˆ˜: {num_modifications}ê°œ")
            return num_modifications

        except Exception as e:
            logger.error(f"ìˆ˜ì • ë¬¸ì¥ ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
            return 3  # ê¸°ë³¸ê°’ ë°˜í™˜
    
    def calculate_lexical_modification_count(
        self,
        current_ratio: float,
        target_min: float,
        target_max: float,
        analysis_result: Dict[str, Any]
    ) -> int:
        """
        CEFR A1~A2 NVJD ë¹„ìœ¨ì´ ê¸°ì¤€ì„ ë²—ì–´ë‚¬ì„ ë•Œ ì¡°ì •í•´ì•¼ í•  ì–´íœ˜ ìˆ˜ ê³„ì‚°

        Args:
            current_ratio: í˜„ì¬ A1~A2 ì–´íœ˜ ë¹„ìœ¨
            target_min: ëª©í‘œ ìµœì†Œ ë¹„ìœ¨ (ex: 0.571)
            target_max: ëª©í‘œ ìµœëŒ€ ë¹„ìœ¨ (ex: 0.703)
            analysis_result: {
                'content_lemmas': ì „ì²´ content lemma ìˆ˜ (table_02_detailed_tokens),
                'propn_lemma_count': ê³ ìœ ëª…ì‚¬ ìˆ˜ (table_09_pos_distribution),
                'cefr_a1_NVJD_lemma_count': A1 ìˆ˜ì¤€ NVJD ì–´íœ˜ ìˆ˜ (table_11_lemma_metrics),
                'cefr_a2_NVJD_lemma_count': A2 ìˆ˜ì¤€ NVJD ì–´íœ˜ ìˆ˜ (table_11_lemma_metrics)
            }

        Returns:
            int: ì¡°ì •ì´ í•„ìš”í•œ ì–´íœ˜ ìˆ˜ (1ê°œ ì´ìƒ)
        """
        try:
            content_lemmas = analysis_result.get('content_lemmas', 0)
            propn_lemma_count = analysis_result.get('propn_lemma_count', 0)
            a1_count = analysis_result.get('cefr_a1_NVJD_lemma_count', 0)
            a2_count = analysis_result.get('cefr_a2_NVJD_lemma_count', 0)

            nvjd_total = content_lemmas - propn_lemma_count
            a1a2_total = a1_count + a2_count

            if nvjd_total == 0:
                return 0

            if target_min <= current_ratio <= target_max:
                num_modifications = 0  # ê¸°ì¤€ ì•ˆì— ìˆìœ¼ë©´ ì¡°ì • í•„ìš” ì—†ìŒ
            elif current_ratio < target_min:
                # A1~A2 ë¹„ìœ¨ì´ ë„ˆë¬´ ë‚®ìŒ â†’ ë” ì¶”ê°€í•´ì•¼ í•¨
                required = (target_min * nvjd_total) - a1a2_total
                num_modifications = max(1, math.ceil(required))
            else:
                # A1~A2 ë¹„ìœ¨ì´ ë„ˆë¬´ ë†’ìŒ â†’ ì¤„ì—¬ì•¼ í•¨
                excess = a1a2_total - (target_max * nvjd_total)
                num_modifications = max(1, math.ceil(excess))

            logger.info(f"Lexical ìˆ˜ì • í•„ìš”: í˜„ì¬={current_ratio:.3f}, ëª©í‘œ=[{target_min:.3f}, {target_max:.3f}], "
                        f"ì´ìˆ˜={nvjd_total}, A1A2={a1a2_total}, ì¡°ì •={num_modifications}ê°œ")

            return num_modifications

        except Exception as e:
            logger.error(f"Lexical ìˆ˜ì • ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
            return 3  # ì˜ˆì™¸ ë°œìƒ ì‹œ ê¸°ë³¸ê°’

# ì „ì—­ í”„ë¡¬í”„íŠ¸ ë¹Œë” ì¸ìŠ¤í„´ìŠ¤
prompt_builder = PromptBuilder() 