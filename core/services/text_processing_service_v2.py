import time
import asyncio
from typing import List, Dict, Any
from models.request import SyntaxFixRequest, ToleranceAbs, ToleranceRatio
from models.response import SyntaxFixResponse, StepResult
from core.analyzer import analyzer
from core.metrics import metrics_extractor
from core.judge import judge
from core.llm.syntax_fixer import syntax_fixer
from core.llm.lexical_fixer import lexical_fixer
from core.llm.prompt_builder import prompt_builder
from utils.logging import logger
# import nltk
# nltk.download('punkt')

class TextProcessingService:
    """í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì„œë¹„ìŠ¤ (êµ¬ë¬¸/ì–´íœ˜ ìˆ˜ì •)"""
    
    def __init__(self):
        self.max_concurrent = 10  # ê¸°ë³¸ ë°°ì¹˜ ë™ì‹œ ì²˜ë¦¬ ê°œìˆ˜
    
    async def fix_revise_single(self, request: SyntaxFixRequest) -> SyntaxFixResponse:
        """
        ê²°í•© ë¦¬ë¹„ì „: êµ¬ë¬¸ ìˆ˜ì • â†’ êµ¬ë¬¸ ê²°ê³¼ ë¶„ì„ â†’ ì–´íœ˜ í†µê³¼ ì—¬ë¶€ í™•ì¸ â†’ í•„ìš” ì‹œ ì–´íœ˜ ë‹¨ê³„ë¡œ ë¶„ê¸°
        """
        total_start_time = time.time()
        step_results = []
        try:
            logger.info(f"[revise] Start: request_id={request.request_id}, Text={len(request.text)}ê¸€ì")

            # ê¸°ë³¸ í—ˆìš©ì˜¤ì°¨ ë¡œë”©
            tolerance_abs = ToleranceAbs()
            tolerance_ratio = ToleranceRatio()
            referential_clauses = request.referential_clauses or ""

            # 1) í…ìŠ¤íŠ¸ ë¶„ì„
            analysis_start_time = time.time()
            try:
                original_analysis = await analyzer.analyze(request.text, include_syntax=True)
                original_metrics = metrics_extractor.extract(original_analysis)
                original_evaluation = judge.evaluate(original_metrics, request.master, tolerance_abs, tolerance_ratio)

                original_metrics_dict = {
                    'AVG_SENTENCE_LENGTH': original_metrics.get('AVG_SENTENCE_LENGTH', 0),
                    'All_Embedded_Clauses_Ratio': original_metrics.get('All_Embedded_Clauses_Ratio', 0),
                    'CEFR_NVJD_A1A2_lemma_ratio': original_metrics.get('CEFR_NVJD_A1A2_lemma_ratio', 0)
                }

                step_results.append(StepResult(
                    step_name="ì›ë³¸ ì§€ë¬¸ ë¶„ì„",
                    success=True,
                    status=f"[revise] ì›ë³¸ ë¶„ì„ ì™„ë£Œ - êµ¬ë¬¸: {original_evaluation.syntax_pass}, ì–´íœ˜: {original_evaluation.lexical_pass}",
                    processing_time=time.time() - analysis_start_time,
                    details={
                        "syntax_pass": original_evaluation.syntax_pass,
                        "lexical_pass": original_evaluation.lexical_pass,
                        "details": original_evaluation.details
                    }
                ))
                
                logger.info(f"[revise] ì›ë³¸ ë¶„ì„ ì™„ë£Œ - êµ¬ë¬¸: {original_evaluation.syntax_pass}, ì–´íœ˜: {original_evaluation.lexical_pass}")
            except Exception as e:
                step_results.append(StepResult(
                    step_name="ì›ë³¸ ì§€ë¬¸ ë¶„ì„",
                    status=f"[revise] ì›ë³¸ ë¶„ì„ ì‹¤íŒ¨ - {str(e)}",
                    success=False,
                    processing_time=time.time() - analysis_start_time,
                    error_message=str(e)
                ))
                raise

            # 2) êµ¬ë¬¸ PASS & ì–´íœ˜ PASS â†’ ì¦‰ì‹œ ì¢…ë£Œ
            if original_evaluation.syntax_pass == "PASS" and original_evaluation.lexical_pass == "PASS":
                total_time = time.time() - total_start_time
                logger.info(f"[revise] êµ¬ë¬¸ & ì–´íœ˜ ëª¨ë‘ í†µê³¼ â†’ ì¦‰ì‹œ ì¢…ë£Œ")
                step_results.append(StepResult(
                    step_name="êµ¬ë¬¸ ìˆ˜ì •",
                    status=f"[revise] êµ¬ë¬¸ & ì–´íœ˜ ëª¨ë‘ í†µê³¼",
                    success=True,
                    processing_time=0.0,
                    details={
                        "skipped": True,
                        "reason": "êµ¬ë¬¸ í†µê³¼ë¡œ ìŠ¤í‚µ",
                        "candidates_generated": 0,
                        "candidates_passed": 0
                    }
                ))
                step_results.append(StepResult(
                    step_name="ì–´íœ˜ ìˆ˜ì •",
                    status=f"[revise] êµ¬ë¬¸ & ì–´íœ˜ ëª¨ë‘ í†µê³¼",
                    success=True,
                    processing_time=0.0,
                    details={
                        "skipped": True,
                        "reason": "êµ¬ë¬¸ í†µê³¼ë¡œ ìŠ¤í‚µ",
                        "candidates_generated": 0,
                        "candidates_passed": 0
                    }
                ))
                
                return SyntaxFixResponse(
                    request_id=request.request_id,
                    overall_success=True,
                    original_text=request.text,
                    final_text=request.text,
                    revision_success=True,
                    step_results=step_results,
                    original_metrics=original_metrics_dict,
                    final_metrics=original_metrics_dict,
                    candidates_generated=0,
                    candidates_passed=0,
                    total_processing_time=total_time
                )
            
            # 3) êµ¬ë¬¸ PASS & ì–´íœ˜ FAIL â†’ ë°”ë¡œ ì–´íœ˜ ìˆ˜ì •ìœ¼ë¡œ ë¶„ê¸°
            if original_evaluation.syntax_pass == "PASS" and original_evaluation.lexical_pass == "FAIL":
                logger.info("=" * 80)
                logger.info("âš¡ [REVISE] êµ¬ë¬¸ í†µê³¼ & ì–´íœ˜ ì‹¤íŒ¨ â†’ ë°”ë¡œ ì–´íœ˜ ìˆ˜ì •ìœ¼ë¡œ ë¶„ê¸°")
                logger.info("=" * 80)
                logger.info(f"ğŸ“Š ì›ë³¸ ì§€í‘œ:")
                logger.info(f"   - í‰ê·  ë¬¸ì¥ ê¸¸ì´: {original_metrics.AVG_SENTENCE_LENGTH:.3f} âœ… PASS")
                logger.info(f"   - ë‚´í¬ì ˆ ë¹„ìœ¨: {original_metrics.All_Embedded_Clauses_Ratio:.3f} âœ… PASS")
                logger.info(f"   - CEFR A1A2 ë¹„ìœ¨: {original_metrics.CEFR_NVJD_A1A2_lemma_ratio:.4f} âŒ FAIL")
                logger.info("=" * 80)
                
                selected_text = request.text
                candidates_generated = 0
                candidates_passed = 0
                
                # ì–´íœ˜ ìˆ˜ì • ë‹¨ê³„ë¡œ ì§ì ‘ ì´ë™ (êµ¬ë¬¸ ìˆ˜ì • ë‹¨ê³„ ìŠ¤í‚µ)
                step_results.append(StepResult(
                    step_name="êµ¬ë¬¸ ìˆ˜ì •",
                    status=f"[revise] syntax PASS & vocab FAIL â†’ ì–´íœ˜ ìˆ˜ì • ëª¨ë“ˆ",
                    success=True,
                    processing_time=0.0,
                    details={
                        "skipped": True,
                        "reason": "êµ¬ë¬¸ í†µê³¼ë¡œ ìŠ¤í‚µ",
                        "candidates_generated": 0,
                        "candidates_passed": 0
                    }
                ))
                
                
                # ë°”ë¡œ ì–´íœ˜ ìˆ˜ì • ë‹¨ê³„ë¡œ ë¶„ê¸°
                selected_candidate_lexical_pass = "FAIL"  # ì›ë³¸ì´ ì–´íœ˜ ì‹¤íŒ¨í–ˆìœ¼ë¯€ë¡œ
                
            # 4) êµ¬ë¬¸ FAIL â†’ êµ¬ë¬¸ ìˆ˜ì • ìˆ˜í–‰
            elif original_evaluation.syntax_pass == "FAIL":
                logger.info("=" * 80)
                logger.info("ğŸ”§ [REVISE] êµ¬ë¬¸ ìˆ˜ì • ë‹¨ê³„ ì‹œì‘")
                logger.info("=" * 80)
                logger.info(f"ğŸ“Š ì›ë³¸ ì§€í‘œ:")
                logger.info(f"   - í‰ê·  ë¬¸ì¥ ê¸¸ì´: {original_metrics.AVG_SENTENCE_LENGTH:.3f}")
                logger.info(f"   - ë‚´í¬ì ˆ ë¹„ìœ¨: {original_metrics.All_Embedded_Clauses_Ratio:.3f}")
                logger.info(f"   - CEFR A1A2 ë¹„ìœ¨: {original_metrics.CEFR_NVJD_A1A2_lemma_ratio:.4f}")
                logger.info("=" * 80)
                
                selected_text = request.text
                candidates_generated = 0
                candidates_passed = 0
                syntax_candidates_lexical = []
                selected_candidate_lexical_pass = None

                # êµ¬ë¬¸ ìˆ˜ì • ì‹œì‘ ì‹œê°„ ì¸¡ì •
                syntax_fix_start_time = time.time()
                try:
                    # ë¬¸ì œ ì§€í‘œ ê³„ì‚°
                    problematic_metric = prompt_builder.determine_problematic_metric(
                        {
                            'avg_sentence_length': original_metrics.AVG_SENTENCE_LENGTH,
                            'embedded_clauses_ratio': original_metrics.All_Embedded_Clauses_Ratio
                        },
                        request.master, tolerance_abs, tolerance_ratio
                    )

                    # ëª©í‘œ ë²”ìœ„ ê³„ì‚°
                    if problematic_metric == "avg_sentence_length":
                        target_min = request.master.AVG_SENTENCE_LENGTH - tolerance_abs.AVG_SENTENCE_LENGTH
                        target_max = request.master.AVG_SENTENCE_LENGTH + tolerance_abs.AVG_SENTENCE_LENGTH
                        current_value = original_metrics.AVG_SENTENCE_LENGTH
                    else:
                        target_min = request.master.All_Embedded_Clauses_Ratio - tolerance_ratio.All_Embedded_Clauses_Ratio
                        target_max = request.master.All_Embedded_Clauses_Ratio + tolerance_ratio.All_Embedded_Clauses_Ratio
                        current_value = original_metrics.All_Embedded_Clauses_Ratio

                    analysis_result = {
                        'sentence_count': original_metrics.sentence_count,
                        'lexical_tokens': original_metrics.lexical_tokens,
                        'total_clause_sentences': original_metrics.total_clause_sentences
                    }

                    modification_params = prompt_builder.calculate_modification_count(
                        problematic_metric, current_value, target_min, target_max, analysis_result
                    )
                    num_modifications = modification_params['num_modifications']
                    prompt_type = modification_params['prompt_type']

                    avg_target_min = request.master.AVG_SENTENCE_LENGTH - tolerance_abs.AVG_SENTENCE_LENGTH
                    avg_target_max = request.master.AVG_SENTENCE_LENGTH + tolerance_abs.AVG_SENTENCE_LENGTH
                    clause_target_min = request.master.All_Embedded_Clauses_Ratio - tolerance_ratio.All_Embedded_Clauses_Ratio
                    clause_target_max = request.master.All_Embedded_Clauses_Ratio + tolerance_ratio.All_Embedded_Clauses_Ratio

                    candidates, selected_text, final_metrics, final_evaluation, total_candidates_generated = await syntax_fixer.fix_syntax_with_params(
                        text=request.text,
                        avg_target_min=avg_target_min,
                        avg_target_max=avg_target_max,
                        clause_target_min=clause_target_min,
                        clause_target_max=clause_target_max,
                        current_metrics=original_metrics_dict,
                        num_modifications=num_modifications,
                        problematic_metric=problematic_metric,
                        referential_clauses=referential_clauses,
                        prompt_type=prompt_type
                    )
                    candidates_generated = total_candidates_generated
                    candidates_passed = len(candidates)

                    # ìµœì¢… ì„ íƒëœ í›„ë³´ì˜ ì–´íœ˜ í†µê³¼ ì—¬ë¶€ëŠ” final_metricsì—ì„œ ì§ì ‘ ê³„ì‚°í•˜ì—¬ ì¬ë¶„ì„ì„ í”¼í•¨
                    lex_target_min = request.master.CEFR_NVJD_A1A2_lemma_ratio - tolerance_ratio.CEFR_NVJD_A1A2_lemma_ratio
                    lex_target_max = request.master.CEFR_NVJD_A1A2_lemma_ratio + tolerance_ratio.CEFR_NVJD_A1A2_lemma_ratio
                    lex_current = final_metrics.CEFR_NVJD_A1A2_lemma_ratio
                    selected_candidate_lexical_pass = "PASS" if lex_target_min <= lex_current <= lex_target_max else "FAIL"

                    logger.info("=" * 80)
                    logger.info("âœ… [REVISE] êµ¬ë¬¸ ìˆ˜ì • ì™„ë£Œ")
                    logger.info("=" * 80)
                    logger.info(f"ğŸ“Š ìµœì¢… êµ¬ë¬¸ ì§€í‘œ:")
                    logger.info(f"   - í‰ê·  ë¬¸ì¥ ê¸¸ì´: {final_metrics.AVG_SENTENCE_LENGTH:.3f}")
                    logger.info(f"   - ë‚´í¬ì ˆ ë¹„ìœ¨: {final_metrics.All_Embedded_Clauses_Ratio:.3f}")
                    logger.info(f"ğŸ“Š ì–´íœ˜ í‰ê°€:")
                    logger.info(f"   - CEFR A1A2 ë¹„ìœ¨: {lex_current:.4f}")
                    logger.info(f"   - ëª©í‘œ ë²”ìœ„: [{lex_target_min:.4f} ~ {lex_target_max:.4f}]")
                    logger.info(f"   - ì–´íœ˜ í†µê³¼ ì—¬ë¶€: {selected_candidate_lexical_pass}")
                    logger.info("=" * 80)

                    step_results.append(StepResult(
                        step_name="êµ¬ë¬¸ ìˆ˜ì •",
                        status=f"[revise] syntax revision success & vocab {selected_candidate_lexical_pass}",
                        success=True,
                        processing_time=time.time() - syntax_fix_start_time,
                        details={
                            "skipped": False,
                            "candidates_generated": candidates_generated,
                            "candidates_passed": candidates_passed,
                            "selected_candidate_lexical": {
                                "lexical_pass": selected_candidate_lexical_pass,
                                "cefr_a1a2_ratio": lex_current,
                                "target_min": lex_target_min,
                                "target_max": lex_target_max
                            }
                        }
                    ))
                    
                    # ì–´íœ˜ ìˆ˜ì • ë‹¨ê³„ ê¸°ë¡ (ì–´íœ˜ PASSë¡œ ë³„ë„ ìˆ˜ì • ë¶ˆí•„ìš”)
                    # step_results.append(StepResult(
                    #     step_name="ì–´íœ˜ ìˆ˜ì •",
                    #     status="[revise] lexical check PASS (no lexical fixing needed)",
                    #     success=True,
                    #     processing_time=0.0,
                    #     details={
                    #         "skipped": True,
                    #         "reason": "êµ¬ë¬¸ ìˆ˜ì •ëœ ì§€ë¬¸ì´ ì–´íœ˜ ì§€í‘œë„ í†µê³¼í•˜ì—¬ ì–´íœ˜ ìˆ˜ì • ë¶ˆí•„ìš”",
                    #         "lexical_pass": selected_candidate_lexical_pass,
                    #         "cefr_a1a2_ratio": lex_current,
                    #         "target_min": lex_target_min,
                    #         "target_max": lex_target_max
                    #     }
                    # ))

                except Exception as e:
                    step_results.append(StepResult(
                        step_name="êµ¬ë¬¸ ìˆ˜ì •",
                        status=f"[revise] syntax revision FAIL - {str(e)}",
                        success=False,
                        processing_time=time.time() - syntax_fix_start_time,
                        error_message=str(e)
                    ))
                    # êµ¬ë¬¸ ìˆ˜ì • ì‹¤íŒ¨ ì‹œ ì¡°ê¸° ë°˜í™˜
                    total_time = time.time() - total_start_time
                    return SyntaxFixResponse(
                        request_id=request.request_id,
                        overall_success=False,
                        original_text=request.text,
                        final_text=None,
                        revision_success=False,
                        step_results=step_results,
                        original_metrics=original_metrics_dict,
                        final_metrics=None,
                        candidates_generated=candidates_generated,
                        candidates_passed=candidates_passed,
                        total_processing_time=total_time,
                        error_message=str(e)
                    )
            else:
                # êµ¬ë¬¸ PASS & ì–´íœ˜ PASSì¸ ê²½ìš°ëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë¨
                logger.error("[revise] ì˜ˆìƒì¹˜ ëª»í•œ ë¶„ê¸°")
                raise Exception("ì˜ˆìƒì¹˜ ëª»í•œ í‰ê°€ ê²°ê³¼ ì¡°í•©")

            # 5) ì„ íƒëœ í…ìŠ¤íŠ¸ì˜ ìµœì¢… ì§€í‘œ ì¤€ë¹„ (ì¬ë¶„ì„ ì—†ì´ ê¸°ì¡´ ê²°ê³¼ í™œìš©)
            if original_evaluation.syntax_pass == "PASS":
                # êµ¬ë¬¸ì´ ì›ë˜ í†µê³¼í–ˆìœ¼ë©´ ì›ë³¸ ì§€í‘œ ì‚¬ìš©
                final_metrics_dict = original_metrics_dict.copy()
            else:
                # êµ¬ë¬¸ ìˆ˜ì •ì„ ê±°ì³¤ìœ¼ë©´ êµ¬ë¬¸ ìˆ˜ì • ê²°ê³¼ì˜ ì§€í‘œ ì‚¬ìš©
                final_metrics_dict = {
                    'AVG_SENTENCE_LENGTH': final_metrics.AVG_SENTENCE_LENGTH,
                    'All_Embedded_Clauses_Ratio': final_metrics.All_Embedded_Clauses_Ratio,
                    'CEFR_NVJD_A1A2_lemma_ratio': final_metrics.CEFR_NVJD_A1A2_lemma_ratio
                }

            # 6) ì–´íœ˜ í†µê³¼ ì—¬ë¶€ì— ë”°ë¥¸ ë¶„ê¸°
            if selected_candidate_lexical_pass == "PASS":
                # ì–´íœ˜ í†µê³¼ â†’ ìµœì¢… ì¢…ë£Œ
                total_time = time.time() - total_start_time
                logger.info(f"[revise] ì„ íƒëœ í…ìŠ¤íŠ¸ ì–´íœ˜ í†µê³¼ â†’ ìµœì¢… ì¢…ë£Œ")
                return SyntaxFixResponse(
                    request_id=request.request_id,
                    overall_success=True,
                    original_text=request.text,
                    final_text=selected_text,
                    revision_success=True,
                    step_results=step_results,
                    original_metrics=original_metrics_dict,
                    final_metrics=final_metrics_dict,
                    candidates_generated=candidates_generated,
                    candidates_passed=candidates_passed,
                    total_processing_time=total_time
                )

            # 7) ì–´íœ˜ ìˆ˜ì • ë‹¨ê³„ (lexical_fixer ì—°ë™)
            logger.info("=" * 80)
            logger.info("ğŸ“š [REVISE] ì–´íœ˜ ìˆ˜ì • ë‹¨ê³„ ì‹œì‘")
            logger.info("=" * 80)
            
            t3=time.time()
            try:
                # ë¶„ê¸°ë³„ í…ìŠ¤íŠ¸ ë° ì§€í‘œ ì†ŒìŠ¤ ê²°ì •
                if original_evaluation.syntax_pass == "PASS":
                    # ì›ë³¸ êµ¬ë¬¸ PASS â†’ ì›ë³¸ í…ìŠ¤íŠ¸ ê¸°ì¤€
                    text_for_lex = request.text
                    src_metrics = original_metrics
                    logger.info("ğŸ“ ì›ë³¸ í…ìŠ¤íŠ¸ ê¸°ì¤€ (êµ¬ë¬¸ ìˆ˜ì • ì—†ìŒ)")
                else:
                    # êµ¬ë¬¸ ìˆ˜ì • í›„ í›„ë³´ ì„ íƒ â†’ ì„ íƒ í…ìŠ¤íŠ¸ ê¸°ì¤€
                    text_for_lex = selected_text
                    # final_metricsì—ëŠ” NVJD ì¹´ìš´íŠ¸ê°€ í¬í•¨ë¨ (metrics_extractor í™•ì¥)
                    src_metrics = final_metrics
                    logger.info("ğŸ“ êµ¬ë¬¸ ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ ê¸°ì¤€")

                # NVJD ì¹´ìš´íŠ¸ ë° í˜„ì¬ ë¹„ìœ¨ ì‚°ì¶œ
                nvjd_total = max(1, int(src_metrics.content_lemmas or 0) - int(src_metrics.propn_lemma_count or 0))
                nvjd_a1a2 = int(src_metrics.cefr_a1_NVJD_lemma_count or 0) + int(src_metrics.cefr_a2_NVJD_lemma_count or 0)
                current_ratio = float(src_metrics.CEFR_NVJD_A1A2_lemma_ratio)

                logger.info(f"ğŸ“Š í˜„ì¬ ì–´íœ˜ ì§€í‘œ:")
                logger.info(f"   - NVJD ì´ ë ˜ë§ˆ: {nvjd_total}")
                logger.info(f"   - NVJD A1A2 ë ˜ë§ˆ: {nvjd_a1a2}")
                logger.info(f"   - í˜„ì¬ CEFR A1A2 ë¹„ìœ¨: {current_ratio:.4f}")

                # ìˆ˜ì • ë‹¨ì–´ ìˆ˜ ê³„ì‚° (í”„ë¡¬í”„íŠ¸ ë¹Œë”)
                lex_calc = prompt_builder.calculate_lexical_modification_count_nvjd(
                    current_ratio=current_ratio,
                    nvjd_total_lemma_count=nvjd_total,
                    nvjd_a1a2_lemma_count=nvjd_a1a2,
                    master=request.master,
                    tolerance_ratio=tolerance_ratio
                )
                lex_num_mods = int(lex_calc.get('num_modifications', 0))
                lex_direction = lex_calc.get('direction', 'increase')
                
                logger.info(f"ğŸ¯ ì–´íœ˜ ìˆ˜ì • ê³„íš:")
                logger.info(f"   - ìˆ˜ì • ë°©í–¥: {lex_direction}")
                logger.info(f"   - ìˆ˜ì • ë‹¨ì–´ ìˆ˜: {lex_num_mods}")
                logger.info(f"   - ëª©í‘œ ë²”ìœ„: {lex_calc.get('target_lower', 0):.4f} ~ {lex_calc.get('target_upper', 0):.4f}")
                logger.info("=" * 80)

                # ì–´íœ˜ í›„ë³´ ìƒì„± ë° ì·¨í•© (0ì¸ ê²½ìš°ë„ í”„ë¡¬í”„íŠ¸ ìµœì†Œ 1ê°œ ìˆ˜í–‰í• ì§€ ì •ì±…ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥)
                normalized_text_for_lex = " ".join(text_for_lex.split())
                lex_mods, lex_selected_text, lex_metrics, _lex_eval, lex_candidates_generated = await lexical_fixer.fix_lexical_with_params(
                    text=normalized_text_for_lex,
                    master=request.master,
                    tolerance_ratio=tolerance_ratio,
                    current_cefr_ratio=current_ratio,
                    direction=lex_direction,
                    nvjd_total_lemma_count=nvjd_total,
                    nvjd_a1a2_lemma_count=nvjd_a1a2,
                    cefr_breakdown=src_metrics.cefr_breakdown
                )

                logger.info("=" * 80)
                logger.info("âœ… [REVISE] ì–´íœ˜ ìˆ˜ì • ì™„ë£Œ")
                logger.info("=" * 80)
                logger.info(f"ğŸ“Š ì–´íœ˜ í›„ë³´ ìƒì„±: {lex_candidates_generated}ê°œ")
                logger.info(f"ğŸ“‹ ìµœì¢… ì–´íœ˜ ì§€í‘œ:")
                logger.info(f"   - CEFR A1A2 ë¹„ìœ¨: {lex_metrics.get('CEFR_NVJD_A1A2_lemma_ratio', 0):.4f}")
                logger.info(f"   - NVJD ì´ ë ˜ë§ˆ: {lex_metrics.get('NVJD_total_lemma_count', 0)}")
                logger.info(f"   - NVJD A1A2 ë ˜ë§ˆ: {lex_metrics.get('NVJD_A1A2_lemma_count', 0)}")
                logger.info("=" * 80)
                
                step_results.append(StepResult(
                    step_name="ì–´íœ˜ ìˆ˜ì •",
                    status=f"[revise] vocab revision success",
                    success=True,
                    processing_time=time.time() - t3,
                    details={
                        "current_ratio": current_ratio,
                        "nvjd_total_lemma_count": nvjd_total,
                        "nvjd_a1a2_lemma_count": nvjd_a1a2,
                        "num_modifications": lex_num_mods,
                        "direction": lex_direction,
                        "lexical_candidates_generated": lex_candidates_generated,
                        "lexical_candidates": lex_metrics.get('lexical_candidates'),
                        "lexical_sheet_data_merged": lex_metrics.get('lexical_sheet_data_merged')
                    }
                ))

                total_time = time.time() - total_start_time
                return SyntaxFixResponse(
                    request_id=request.request_id,
                    overall_success=True,
                    original_text=request.text,
                    final_text=selected_text,
                    revision_success=True,
                    step_results=step_results,
                    original_metrics=original_metrics_dict,
                    final_metrics=final_metrics_dict,
                    candidates_generated=candidates_generated,
                    candidates_passed=candidates_passed,
                    total_processing_time=total_time,
                    error_message=str(e)
                )
            except Exception as e:
                step_results.append(StepResult(
                    step_name="ì–´íœ˜ ìˆ˜ì •",
                    status=f"[revise] vocab revision FAIL - {str(e)}",
                    success=False,
                    processing_time=time.time() - t3,
                    error_message=str(e)
                ))

                total_time = time.time() - total_start_time
                return SyntaxFixResponse(
                    request_id=request.request_id,
                    overall_success=True,
                    original_text=request.text,
                    final_text=selected_text,
                    revision_success=False,
                    step_results=step_results,
                    original_metrics=original_metrics_dict,
                    final_metrics=final_metrics_dict,
                    candidates_generated=candidates_generated,
                    candidates_passed=candidates_passed,
                    total_processing_time=total_time,
                    error_message=str(e)
                )
        except Exception as e:
            total_time = time.time() - total_start_time
            logger.error(f"[revise] ì „ì²´ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
            return SyntaxFixResponse(
                request_id=request.request_id,
                overall_success=False,
                original_text=request.text,
                final_text=None,
                revision_success=False,
                step_results=step_results,
                original_metrics=None,
                final_metrics=None,
                candidates_generated=0,
                candidates_passed=0,
                total_processing_time=total_time,
                error_message=str(e)
            )

    async def fix_revise_batch(self, items: List[SyntaxFixRequest], max_concurrent: int = None) -> List[SyntaxFixResponse]:
        """
        ê²°í•© ë¦¬ë¹„ì „ ë°°ì¹˜ ì²˜ë¦¬
        """
        if max_concurrent is None:
            max_concurrent = self.max_concurrent

        logger.info(f"[revise] ë°°ì¹˜ ì‹œì‘: {len(items)}ê°œ, ë™ì‹œ ì²˜ë¦¬={max_concurrent}")
        semaphore = asyncio.Semaphore(max_concurrent)

        async def process_item(item: SyntaxFixRequest) -> SyntaxFixResponse:
            async with semaphore:
                return await self.fix_revise_single(item)

        tasks = [process_item(item) for item in items]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        processed: List[SyntaxFixResponse] = []
        for i, r in enumerate(results):
            if isinstance(r, Exception):
                logger.error(f"[revise] í•­ëª© {i} ì‹¤íŒ¨: {str(r)}")
                processed.append(SyntaxFixResponse(
                    request_id=items[i].request_id,
                    overall_success=False,
                    original_text=items[i].text,
                    final_text=None,
                    revision_success=False,
                    step_results=[],
                    original_metrics=None,
                    final_metrics=None,
                    candidates_generated=0,
                    candidates_passed=0,
                    total_processing_time=0.0,
                    error_message=str(r)
                ))
            else:
                processed.append(r)
        logger.info(f"[revise] ë°°ì¹˜ ì™„ë£Œ: {len(processed)}ê°œ ê²°ê³¼")
        return processed

# ì „ì—­ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
text_processing_service = TextProcessingService() 